{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T13:49:23.142572700Z",
     "start_time": "2023-10-28T13:49:23.108631600Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from src.data.smr_datamodule import SMR_Data\n",
    "from src.utils.device import print_data_info\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c34c4139fb8dfae5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T13:47:07.969842600Z",
     "start_time": "2023-10-28T13:46:11.838798600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Found sessions: ['Session_1', 'Session_2', 'Session_3', 'Session_4', 'Session_5', 'Session_6', 'Session_7'] for subject S5\n",
      "INFO:root:Subject S5 loading...\n",
      "INFO:root:Loading session Session_1 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noisechan [24.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Noisy channels found: [24.0], each channel will be averaged with 4 neighbors\n",
      "INFO:root:Bandpass filtering the data between 8-20 Hz\n",
      "INFO:root:Preprocessing the data ...\n",
      "INFO:root:Data shape before preprocessing: (150, 62, 12000)\n",
      "INFO:root:Data shape after preprocessing: (150, 62, 4500)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_1 (6, 62, 4500)\n",
      "run_2 (7, 62, 4500)\n",
      "run_3 (6, 62, 4500)\n",
      "run_4 (7, 62, 4500)\n",
      "run_5 (9, 62, 4500)\n",
      "run_6 (6, 62, 4500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:1/7 sessions loaded\n",
      "INFO:root:Loading session Session_2 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noisechan None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Bandpass filtering the data between 8-20 Hz\n",
      "INFO:root:Preprocessing the data ...\n",
      "INFO:root:Data shape before preprocessing: (150, 62, 12000)\n",
      "INFO:root:Data shape after preprocessing: (150, 62, 4500)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_1 (11, 62, 4500)\n",
      "run_2 (7, 62, 4500)\n",
      "run_3 (9, 62, 4500)\n",
      "run_4 (13, 62, 4500)\n",
      "run_5 (9, 62, 4500)\n",
      "run_6 (7, 62, 4500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:2/7 sessions loaded\n",
      "INFO:root:Loading session Session_3 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noisechan None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Bandpass filtering the data between 8-20 Hz\n",
      "INFO:root:Preprocessing the data ...\n",
      "INFO:root:Data shape before preprocessing: (150, 62, 12000)\n",
      "INFO:root:Data shape after preprocessing: (150, 62, 4500)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_1 (12, 62, 4500)\n",
      "run_2 (15, 62, 4500)\n",
      "run_3 (13, 62, 4500)\n",
      "run_4 (14, 62, 4500)\n",
      "run_5 (17, 62, 4500)\n",
      "run_6 (22, 62, 4500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:3/7 sessions loaded\n",
      "INFO:root:Loading session Session_4 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noisechan None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Bandpass filtering the data between 8-20 Hz\n",
      "INFO:root:Preprocessing the data ...\n",
      "INFO:root:Data shape before preprocessing: (150, 62, 12000)\n",
      "INFO:root:Data shape after preprocessing: (150, 62, 4500)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_1 (13, 62, 4500)\n",
      "run_2 (12, 62, 4500)\n",
      "run_3 (15, 62, 4500)\n",
      "run_4 (11, 62, 4500)\n",
      "run_5 (12, 62, 4500)\n",
      "run_6 (15, 62, 4500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:4/7 sessions loaded\n",
      "INFO:root:Loading session Session_5 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noisechan None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Bandpass filtering the data between 8-20 Hz\n",
      "INFO:root:Preprocessing the data ...\n",
      "INFO:root:Data shape before preprocessing: (150, 62, 12000)\n",
      "INFO:root:Data shape after preprocessing: (150, 62, 4500)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_1 (15, 62, 4500)\n",
      "run_2 (6, 62, 4500)\n",
      "run_3 (21, 62, 4500)\n",
      "run_4 (20, 62, 4500)\n",
      "run_5 (18, 62, 4500)\n",
      "run_6 (14, 62, 4500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:5/7 sessions loaded\n",
      "INFO:root:Loading session Session_6 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noisechan None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Bandpass filtering the data between 8-20 Hz\n",
      "INFO:root:Preprocessing the data ...\n",
      "INFO:root:Data shape before preprocessing: (150, 62, 12000)\n",
      "INFO:root:Data shape after preprocessing: (150, 62, 4500)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_1 (15, 62, 4500)\n",
      "run_2 (7, 62, 4500)\n",
      "run_3 (11, 62, 4500)\n",
      "run_4 (18, 62, 4500)\n",
      "run_5 (12, 62, 4500)\n",
      "run_6 (8, 62, 4500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:6/7 sessions loaded\n",
      "INFO:root:Loading session Session_7 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noisechan None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Bandpass filtering the data between 8-20 Hz\n",
      "INFO:root:Preprocessing the data ...\n",
      "INFO:root:Data shape before preprocessing: (150, 62, 12000)\n",
      "INFO:root:Data shape after preprocessing: (150, 62, 4500)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_1 (20, 62, 4500)\n",
      "run_2 (22, 62, 4500)\n",
      "run_3 (20, 62, 4500)\n",
      "run_4 (22, 62, 4500)\n",
      "run_5 (25, 62, 4500)\n",
      "run_6 (19, 62, 4500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:7/7 sessions loaded\n",
      "C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\numpy\\lib\\arraysetops.py:733: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n",
      "INFO:root:Sesssion Session_7 appended, final shapes for each run:\n",
      "INFO:root:Run 1 shape: (92, 62, 4500)\n",
      "INFO:root:Run 2 shape: (76, 62, 4500)\n",
      "INFO:root:Run 3 shape: (95, 62, 4500)\n",
      "INFO:root:Run 4 shape: (105, 62, 4500)\n",
      "INFO:root:Run 5 shape: (102, 62, 4500)\n",
      "INFO:root:Run 6 shape: (91, 62, 4500)\n",
      "INFO:root:Preparing data...\n",
      "INFO:root:Train data info:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (460, 62, 4500)\n",
      "max timepoints:  130.5242172568494\n",
      "min timepoints:  -88.35799849286423\n",
      "mean timepoints:  -0.00032405977194958327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Test data info:\n",
      "INFO:root:Normalizing the data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std timepoints:  4.307553661278638\n",
      "data shape:  (91, 62, 4500)\n",
      "max timepoints:  64.3120209590247\n",
      "min timepoints:  -66.59509069026409\n",
      "mean timepoints:  -0.0010002329798996057\n",
      "std timepoints:  4.4625932339489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train data info:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (460, 62, 4500)\n",
      "max timepoints:  21.422163177147127\n",
      "min timepoints:  -21.422515888547576\n",
      "mean timepoints:  -5.723262841608256e-20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Test data info:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std timepoints:  1.0000000000000036\n",
      "data shape:  (91, 62, 4500)\n",
      "max timepoints:  62.52899999417535\n",
      "min timepoints:  -64.4336862602446\n",
      "mean timepoints:  -4.585871616426793e-05\n",
      "std timepoints:  0.9979242563508113\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path(\"D:\\\\SMR\\\\\")\n",
    "task_name = \"2D\"\n",
    "subject_sessions_dict = {\"S5\": \"all\"}\n",
    "loading_data_mode = \"within_subject\"\n",
    "ival = \"2s:11s:2ms\"\n",
    "bands = [8, 20]\n",
    "chans = \"*\"\n",
    "fallback_neighbors = 4\n",
    "transform = None\n",
    "normalize = {\"norm_type\": \"std\", \"norm_axis\": 0}\n",
    "# normalize = None\n",
    "\n",
    "process_noisy_channels = True\n",
    "ignore_noisy_sessions = False\n",
    "\n",
    "trial_type = \"valid\"\n",
    "\n",
    "smr_datamodule = SMR_Data(data_dir=data_dir,\n",
    "                          task_name=task_name,\n",
    "                          trial_type=trial_type,\n",
    "                          subject_sessions_dict=subject_sessions_dict,\n",
    "                          loading_data_mode=loading_data_mode,\n",
    "                          ival=ival,\n",
    "                          bands=bands,\n",
    "                          chans=chans,\n",
    "                          fallback_neighbors=fallback_neighbors,\n",
    "                          transform=transform,\n",
    "                          normalize=normalize,\n",
    "                          process_noisy_channels=process_noisy_channels,\n",
    "                          ignore_noisy_sessions=ignore_noisy_sessions)\n",
    "smr_datamodule.prepare_dataloader_baseline()\n",
    "train_data = smr_datamodule.train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "474568b42bc295c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T13:49:29.545181900Z",
     "start_time": "2023-10-28T13:49:27.278667700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (460, 62, 4500)\n",
      "max timepoints:  21.422163177147127\n",
      "min timepoints:  -21.422515888547576\n",
      "mean timepoints:  -5.723262841608256e-20\n",
      "std timepoints:  1.0000000000000036\n",
      "(array([0, 1, 2, 3]), array([121,  95, 121, 123], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print_data_info(train_data)\n",
    "import numpy as np\n",
    "print(np.unique(train_data.y, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fb13c7-923d-4135-8c85-ace447ef1ee4",
   "metadata": {},
   "source": [
    "## MNE data format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac99b345-5fbd-4ce0-b223-a467cf2cf6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "460 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "eeg_data = train_data.data\n",
    "# Create an events array from train_data.y and event times\n",
    "events = []\n",
    "for i, label in enumerate(train_data.y):\n",
    "    events.append([i, 0, label])\n",
    "\n",
    "# Convert the events list to a NumPy array\n",
    "events = np.array(events)\n",
    "\n",
    "info = mne.create_info(ch_names=train_data.chans, sfreq=train_data.fs, ch_types=['eeg'] * train_data.nCh)\n",
    "# Create a RawArray object\n",
    "# Create an EpochsArray object\n",
    "epochs = mne.EpochsArray(eeg_data, info, events=events, event_id = {'Left': 0, 'Right': 1, 'Up':2, 'Down':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a6ed803-bdb0-482d-b8d3-5c1147874a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_data = epochs.get_data() \n",
    "labels = epochs.events[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "237d2f07-1b24-4741-bb1c-5e73cd1b4609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(460, 62, 4500)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d587f6c3-7ce5-435e-9b83-9b8d657df4b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(460,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bbc91b0-17fb-49a6-8d63-e6ebd6a98892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Train: 0=97, 1=76,2=96, 3=99, Test: 0=24, 1=19, 2=25, 3=24\n",
      ">Train: 0=96, 1=76,2=97, 3=99, Test: 0=25, 1=19, 2=24, 3=24\n",
      ">Train: 0=97, 1=76,2=97, 3=98, Test: 0=24, 1=19, 2=24, 3=25\n",
      ">Train: 0=97, 1=76,2=97, 3=98, Test: 0=24, 1=19, 2=24, 3=25\n",
      ">Train: 0=97, 1=76,2=97, 3=98, Test: 0=24, 1=19, 2=24, 3=25\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "# enumerate the splits and summarize the distributions\n",
    "for train_ix, test_ix in kfold.split(epochs_data, labels):\n",
    " # select rows\n",
    " train_X, test_X = epochs_data[train_ix], epochs_data[test_ix]\n",
    " train_y, test_y = labels[train_ix], labels[test_ix]\n",
    " # summarize train and test composition\n",
    " train_0, train_1, train_2, train_3 = len(train_y[train_y==0]), len(train_y[train_y==1]), len(train_y[train_y==2]), len(train_y[train_y==3])\n",
    " test_0, test_1, test_2, test_3 = len(test_y[test_y==0]), len(test_y[test_y==1]), len(test_y[test_y==2]), len(test_y[test_y==3])\n",
    " print('>Train: 0=%d, 1=%d,2=%d, 3=%d, Test: 0=%d, 1=%d, 2=%d, 3=%d' % (train_0, train_1,train_2, train_3, test_0, test_1,test_2, test_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "564efd86-e8ce-418b-9e26-33415a342520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Train: 0=96, 1=77,2=99, 3=96, Test: 0=25, 1=18, 2=22, 3=27\n",
      ">Train: 0=96, 1=77,2=99, 3=96, Test: 0=25, 1=18, 2=22, 3=27\n",
      ">Train: 0=90, 1=73,2=98, 3=107, Test: 0=31, 1=22, 2=23, 3=16\n",
      ">Train: 0=100, 1=75,2=90, 3=103, Test: 0=21, 1=20, 2=31, 3=20\n",
      ">Train: 0=102, 1=78,2=98, 3=90, Test: 0=19, 1=17, 2=23, 3=33\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=5, shuffle=False)\n",
    "# enumerate the splits and summarize the distributions\n",
    "for train_ix, test_ix in kfold.split(epochs_data, labels):\n",
    " # select rows\n",
    " train_X, test_X = epochs_data[train_ix], epochs_data[test_ix]\n",
    " train_y, test_y = labels[train_ix], labels[test_ix]\n",
    " # summarize train and test composition\n",
    " train_0, train_1, train_2, train_3 = len(train_y[train_y==0]), len(train_y[train_y==1]), len(train_y[train_y==2]), len(train_y[train_y==3])\n",
    " test_0, test_1, test_2, test_3 = len(test_y[test_y==0]), len(test_y[test_y==1]), len(test_y[test_y==2]), len(test_y[test_y==3])\n",
    " print('>Train: 0=%d, 1=%d,2=%d, 3=%d, Test: 0=%d, 1=%d, 2=%d, 3=%d' % (train_0, train_1,train_2, train_3, test_0, test_1,test_2, test_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce5d02c-5783-4fc4-84d1-ef7f26a24283",
   "metadata": {},
   "source": [
    "## MNE CSP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b6f105b6ab075fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T14:04:36.639670500Z",
     "start_time": "2023-10-28T14:00:15.259241200Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\sklearn\\utils\\metaestimators.py:121: FutureWarning: if_delegate_has_method was deprecated in version 1.1 and will be removed in version 1.3. Use available_if instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank=None\n",
      "    Using tolerance 41 (2.2e-16 eps * 62 dim * 2.9e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 37 (2.2e-16 eps * 62 dim * 2.7e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 48 (2.2e-16 eps * 62 dim * 3.5e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 48 (2.2e-16 eps * 62 dim * 3.5e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 41 (2.2e-16 eps * 62 dim * 2.9e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 37 (2.2e-16 eps * 62 dim * 2.7e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 48 (2.2e-16 eps * 62 dim * 3.5e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 48 (2.2e-16 eps * 62 dim * 3.5e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\sklearn\\utils\\metaestimators.py:121: FutureWarning: if_delegate_has_method was deprecated in version 1.1 and will be removed in version 1.3. Use available_if instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank=None\n",
      "    Using tolerance 40 (2.2e-16 eps * 62 dim * 2.9e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 37 (2.2e-16 eps * 62 dim * 2.7e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 48 (2.2e-16 eps * 62 dim * 3.5e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 48 (2.2e-16 eps * 62 dim * 3.5e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 40 (2.2e-16 eps * 62 dim * 2.9e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 37 (2.2e-16 eps * 62 dim * 2.7e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 48 (2.2e-16 eps * 62 dim * 3.5e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 48 (2.2e-16 eps * 62 dim * 3.5e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\sklearn\\utils\\metaestimators.py:121: FutureWarning: if_delegate_has_method was deprecated in version 1.1 and will be removed in version 1.3. Use available_if instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank=None\n",
      "    Using tolerance 40 (2.2e-16 eps * 62 dim * 2.9e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 37 (2.2e-16 eps * 62 dim * 2.7e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 45 (2.2e-16 eps * 62 dim * 3.3e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 47 (2.2e-16 eps * 62 dim * 3.4e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 40 (2.2e-16 eps * 62 dim * 2.9e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 37 (2.2e-16 eps * 62 dim * 2.7e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 45 (2.2e-16 eps * 62 dim * 3.3e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 47 (2.2e-16 eps * 62 dim * 3.4e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\sklearn\\utils\\metaestimators.py:121: FutureWarning: if_delegate_has_method was deprecated in version 1.1 and will be removed in version 1.3. Use available_if instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank=None\n",
      "    Using tolerance 36 (2.2e-16 eps * 62 dim * 2.6e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 29 (2.2e-16 eps * 62 dim * 2.1e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 44 (2.2e-16 eps * 62 dim * 3.2e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 42 (2.2e-16 eps * 62 dim * 3e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 36 (2.2e-16 eps * 62 dim * 2.6e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 29 (2.2e-16 eps * 62 dim * 2.1e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 44 (2.2e-16 eps * 62 dim * 3.2e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 42 (2.2e-16 eps * 62 dim * 3e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\sklearn\\utils\\metaestimators.py:121: FutureWarning: if_delegate_has_method was deprecated in version 1.1 and will be removed in version 1.3. Use available_if instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank=None\n",
      "    Using tolerance 39 (2.2e-16 eps * 62 dim * 2.8e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 37 (2.2e-16 eps * 62 dim * 2.7e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 46 (2.2e-16 eps * 62 dim * 3.4e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 47 (2.2e-16 eps * 62 dim * 3.4e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 39 (2.2e-16 eps * 62 dim * 2.8e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 37 (2.2e-16 eps * 62 dim * 2.7e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 46 (2.2e-16 eps * 62 dim * 3.4e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 47 (2.2e-16 eps * 62 dim * 3.4e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\sklearn\\utils\\metaestimators.py:121: FutureWarning: if_delegate_has_method was deprecated in version 1.1 and will be removed in version 1.3. Use available_if instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from mne.decoding import CSP\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import bbcpy.functions.helpers as helpers\n",
    "from bbcpy.functions.base import ImportFunc\n",
    "from bbcpy.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Define the number of splits for cross-validation\n",
    "n_splits = 5\n",
    "# Define the cross-validator\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "\n",
    "# Assemble a classifier\n",
    "var = ImportFunc(np.var, axis=2)\n",
    "\n",
    "# MNE csp \n",
    "n_components=8\n",
    "reg=0.2 #float | str | None (default None)allow regularization for covariance estimation|If float (between 0 and 1), shrinkage is used/\n",
    "log=False  # None | bool (default None)\n",
    "cov_est='concat' #‘concat’ | ‘epoch’ (default ‘concat’)\n",
    "transform_into='average_power' #‘average_power’ : the average power of each spatial filter| ‘csp_space’ :  the data in CSP space(default ‘average_power’)\n",
    "norm_trace=True # bool (default False) Normalize class covariance by its trace.\n",
    "cov_method_params=None #dict | None Parameters to pass to mne.compute_covariance().\n",
    "rank=None #None | ‘info’ | ‘full’ | dict\n",
    "component_order='mutual_info' #‘mutual_info’ | ‘alternate’ (default ‘mutual_info’) \n",
    "\n",
    "csp = CSP(n_components=n_components,\n",
    "          reg=reg,\n",
    "          log=log,\n",
    "          cov_est=cov_est,\n",
    "          transform_into=transform_into,\n",
    "          norm_trace=norm_trace,\n",
    "          cov_method_params=cov_method_params,\n",
    "          rank=rank,\n",
    "          component_order=component_order)\n",
    "\n",
    "results = []\n",
    "\n",
    "clf =  make_pipeline(\n",
    "        csp,\n",
    "        # var,\n",
    "        # np.log,\n",
    "        LDA()\n",
    "    )\n",
    "scores = cross_val_score(clf, epochs_data,labels, cv=cv, n_jobs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2115c8ef-58df-4c4f-8e71-4b6140572f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "# Store results for each fold\n",
    "for i, score in enumerate(scores):\n",
    "    results.append([i+1, score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa710ae7-8006-46bc-bcfd-0e9de9d42586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0.532608695652174],\n",
       " [2, 0.4891304347826087],\n",
       " [3, 0.43478260869565216],\n",
       " [4, 0.5652173913043478],\n",
       " [5, 0.44565217391304346]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "837675f6-9c6e-47d6-8b8e-eb3ab9fd76d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0.5217391304347826],\n",
       " [2, 0.5217391304347826],\n",
       " [3, 0.40217391304347827],\n",
       " [4, 0.4891304347826087],\n",
       " [5, 0.40217391304347827]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5aaa5039-2620-43dd-b101-0c8c3dc4390c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0.9876543209876543],\n",
       " [2, 0.9876543209876543],\n",
       " [3, 0.9629629629629629],\n",
       " [4, 0.9382716049382716],\n",
       " [5, 0.8518518518518519]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e1a25b-3c21-4593-a58c-f9543ec7df0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_path = \"./LR_results_MNE/run_3/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b512fb9faeba23",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame from the results\n",
    "subject_name = list(subject_sessions_dict.keys())[0]\n",
    "results_df = pd.DataFrame(results, columns=['fold', 'score'])\n",
    "file_name = f'{subject_name}_results_csp_mne.csv'\n",
    "results_df.to_csv(file_name, index=False)\n",
    "\n",
    "# Calculate mean and standard deviation for each excllev value\n",
    "summary_df = results_df.groupby('fold')[['score']].agg(['mean', 'std'])\n",
    "file_name = f'{subject_name}_summary_csp_mne.csv'\n",
    "summary_df.to_csv(file_name)\n",
    "\n",
    "# Print the results\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c7328c66d6f47d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "epoch_data = train_data\n",
    "labels = train_data.y\n",
    "epoch_data_info = mne.create_info(train_data.chans, train_data.fs, ch_types='eeg', verbose=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12946e5-fe7e-4825-bb01-538656fbc2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_data_info.set_montage(epochs.get_montage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767b9c66-b421-457d-a1f9-cf7ee289368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot CSP patterns estimated on full data for visualization\n",
    "csp.fit_transform(epoch_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8903f64-0032-4ba2-9208-132f422be701",
   "metadata": {},
   "outputs": [],
   "source": [
    "csp.patterns_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21178e3-f2b1-4392-9f23-80f3d7cfeecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "csp.filters_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2024ffcc-7a7a-40da-b9bb-f24dedccd701",
   "metadata": {},
   "outputs": [],
   "source": [
    "csp.plot_patterns(info=epoch_data_info,\n",
    "                  average=0.1,\n",
    "                  ch_type=\"eeg\",\n",
    "                  units=\"Patterns (AU)\", \n",
    "                  size=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3519d7-9ed6-4d19-bdb9-8a8135022f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
