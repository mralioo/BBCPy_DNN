# storage URL to persist optimization results
# for example, you can use SQLite if you set 'sqlite:///example.db'

storage: ${oc.env:PROJECT_ROOT}/logs/sqlite:///./optuna.db
#storage: ${oc.env:PROJECT_ROOT}\logs\sqlite:\\\eegnet_hpo.db
#storage: null

# name of the study to persist optimization results
study_name: eegnet_hpo

# number of parallel workers
n_jobs: 2

# 'minimize' or 'maximize' the objective
direction: maximize

# total number of runs that will be executed
n_trials: 20

# choose Optuna hyperparameter sampler
# you can choose bayesian sampler (tpe), random search (without optimization), grid sampler, and others
# docs: https://optuna.readthedocs.io/en/stable/reference/samplers.html
sampler:
  _target_: optuna.samplers.TPESampler
  seed: 1234
  n_startup_trials: 5 # number of random sampling runs before optimization starts

pruner:
  _target_: optuna.pruners.MedianPruner
  n_startup_trials: 5 # number of random sampling runs before optimization starts
  n_warmup_steps: 0 # number of steps to warmup before pruning starts
  interval_steps: 1 # number of steps between pruning

# define hyperparameter search space

params:
  csp__n_components: [ 4, 6, 8, 10, 12, 14, 16]
#      solver: svd
#      shrinkage: null #'auto' or float, default=None ; Shrinkage parameter, possible values between 0 and 1. If None, no shrinkage is performed.
#      priors: null #array, shape (n_classes,), default=None ; Class priors.

#      store_covariance: False #bool, default=False ; If True, explicitely compute the weighted within-class covariance matrix when solver is 'svd'. The matrix is always computed and stored for the other solvers.
#      tol: 0.0001 #float, default=1e-4 ; Absolute threshold for a singular value of X to be considered significant, used to estimate the rank of X. Dimensions whose singular values are non-significant are discarded. Only used if solver is 'svd'.

#params:
#  LDA:
#    applied:
#      type: categorical
#      choices: [true, false]
#    solver:
#      type: categorical
#      choices: ['svd', 'lsqr', 'eigen']
#    shrinkage:
#      type: categorical
#      choices: [null, 'auto', 0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
#    priors: null  # This is usually left as null unless you have specific priors
#    n_components:
#      type: int
#      low: 1
#      high: 10 # Adjust this based on your number of classes and features
#    store_covariance:
#      type: categorical
#      choices: [true, false]
#    tol:
#      type: float
#      low: 1e-5
#      high: 1e-3