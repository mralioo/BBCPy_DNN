# @package _global_

# overwrite task name so debugging logs are stored in separate folder
task_name: "debug-dnn-win"

# Train
train: False
tune: True

defaults:
  - override /data: smr_datamodule.yaml
  - override /model: eegnet.yaml
  #  - override /model: TSCeption.yaml
  - override /trainer: gpu.yaml
  - override /paths: default.yaml
  - override /extras: default.yaml
  - override /hydra: default.yaml
  - override /callbacks: default.yaml

paths:
  root_dir: ${oc.env:PROJECT_ROOT}
  data_dir: D:\SMR\
  log_dir: ${oc.env:PROJECT_ROOT}\logs
  output_dir: ${hydra:runtime.output_dir}
  work_dir: ${hydra:runtime.cwd}

# disable callbacks and loggers during debugging
#callbacks: null

logger:
  mlflow:
    experiment_name: DEBUG-DNN-TRAIN
    run_name: EEGNet-v1
    #    run_name: TSCeption-v1
    tracking_uri: file:${paths.log_dir}/mlflow/mlruns
#    tags: ${tags}

model:
  net:
    chunk_size: 9000
  plots_settings:
    plot_every_n_epoch: 1

data:
  task_name: "LR"
  ival: 1s:10s:1ms
  chans: [ "*" ]
  classes:
    - "R"
    - "L"
  loading_data_mode: "cross_subject_hpo"
  #  loading_data_mode: "within_subject"
  subject_sessions_dict:
    S2: "all"
    S3: "all"
  #  transform: "TSCeption"
  transform: False
  normalize: { norm_type: "std", norm_axis: 0}
  train_val_split: False
  cross_validation: { num_splits: 3, split_seed: 1234 }
  num_workers: 4
  pin_memory: False

trainer:
  min_epochs: 1 # prevents early stopping
  max_epochs: 2
  # perform a validation loop every N training epochs
  check_val_every_n_epoch: 1

callbacks:
  early_stopping:
    monitor: "val/f1_epoch"
    patience: 20
    mode: "max"

extras:
  ignore_warnings: False
  enforce_tags: False


# sets level of all command line loggers to 'DEBUG'
# https://hydra.cc/docs/tutorials/basic/running_your_app/logging/
hydra:
  job_logging:
    root:
      level: DEBUG

  # use this to also set hydra loggers to 'DEBUG'
  verbose: True


