{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T11:42:07.729095200Z",
     "start_time": "2023-10-24T11:42:07.712101Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the directory where your CSV files are stored\n",
    "csv_dir = \"../local/8_11/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62843368fb71fe7c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-24T12:18:35.932086600Z"
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_lr = {}\n",
    "data_2D = {}\n",
    "\n",
    "# Step 1: Load CSV files and extract relevant information\n",
    "for csv_file in os.listdir(csv_dir):\n",
    "    if csv_file.endswith(\".csv\"):\n",
    "\n",
    "        csv_file_name = os.path.splitext(csv_file)[0]\n",
    "        # print(csv_file_name)\n",
    "        # print(csv_file_name.split(\"_\"))\n",
    "\n",
    "        if len(csv_file_name.split(\"_\")) == 3:\n",
    "            task, model, subject = csv_file_name.split(\"_\")\n",
    "        else:\n",
    "            task, _, model, subject = csv_file_name.split(\"_\")\n",
    "        \n",
    "        df = pd.read_csv(os.path.join(csv_dir, csv_file))\n",
    "\n",
    "        # Step 2: Separate LR and 2D data\n",
    "        if task == \"LR\":\n",
    "            if model in data_lr:\n",
    "                data_lr[model].append(df.assign(subject_name=subject))\n",
    "            else:\n",
    "                data_lr[model] = [df.assign(subject_name=subject)]\n",
    "        if task == \"2D\":\n",
    "            if model in data_2D:\n",
    "                data_2D[model].append(df.assign(subject_name=subject))\n",
    "            else:\n",
    "                data_2D[model] = [df.assign(subject_name=subject)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e255081-f246-40dc-b412-c3b7ba80508e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'csp': [   mean_test/acc  mean_test/f1  mean_val/acc  mean_val/f1  \\\n",
       "  0       0.502165      0.404677      0.545195     0.430741   \n",
       "  \n",
       "     fold_1@training_roc_auc  fold_1@f1_score_Xt-2  \\\n",
       "  0                 0.651381              0.464048   \n",
       "  \n",
       "     fold_1@training_recall_score  fold_1@training_precision_score  \\\n",
       "  0                      0.596598                          0.61752   \n",
       "  \n",
       "     fold_1@training_f1_score  fold_1@f1_score-2_Xt-3  ...  \\\n",
       "  0                  0.538274                0.492057  ...   \n",
       "  \n",
       "     fold_5@training_log_loss  fold_5@test_valid/acc  fold_5@test_valid/recall  \\\n",
       "  0                   0.67288                0.47619                   0.47619   \n",
       "  \n",
       "     fold_5@test_valid/f1  fold_5@test_valid/precision  fold_5@val/acc  \\\n",
       "  0              0.321976                     0.488462         0.55122   \n",
       "  \n",
       "     fold_5@val/recall  fold_5@val/f1  fold_5@val/precision  subject_name  \n",
       "  0            0.55122       0.391747              0.303843           S38  \n",
       "  \n",
       "  [1 rows x 110 columns],\n",
       "     mean_test/acc  mean_test/f1  mean_val/acc  mean_val/f1  \\\n",
       "  0       0.776774      0.776649       0.82375     0.822969   \n",
       "  \n",
       "     fold_1@training_roc_auc  fold_1@f1_score_Xt-2  \\\n",
       "  0                 0.909567                 0.875   \n",
       "  \n",
       "     fold_1@training_recall_score  fold_1@training_precision_score  \\\n",
       "  0                      0.815625                         0.816026   \n",
       "  \n",
       "     fold_1@training_f1_score  fold_1@f1_score-2_Xt-3  ...  \\\n",
       "  0                  0.815539                0.767568  ...   \n",
       "  \n",
       "     fold_5@training_log_loss  fold_5@test_valid/acc  fold_5@test_valid/recall  \\\n",
       "  0                  0.304506               0.793548                  0.793548   \n",
       "  \n",
       "     fold_5@test_valid/f1  fold_5@test_valid/precision  fold_5@val/acc  \\\n",
       "  0              0.793548                     0.793548         0.79375   \n",
       "  \n",
       "     fold_5@val/recall  fold_5@val/f1  fold_5@val/precision  subject_name  \n",
       "  0            0.79375       0.793354              0.796016           S39  \n",
       "  \n",
       "  [1 rows x 110 columns],\n",
       "     mean_test/acc  mean_test/f1  mean_val/acc  mean_val/f1  \\\n",
       "  0       0.612195      0.601744      0.671795     0.667678   \n",
       "  \n",
       "     fold_1@training_roc_auc  fold_1@f1_score_Xt-2  \\\n",
       "  0                 0.745974              0.730351   \n",
       "  \n",
       "     fold_1@training_recall_score  fold_1@training_precision_score  \\\n",
       "  0                      0.682692                         0.682296   \n",
       "  \n",
       "     fold_1@training_f1_score  fold_1@f1_score-2_Xt-3  ...  \\\n",
       "  0                   0.68208                0.615863  ...   \n",
       "  \n",
       "     fold_5@training_log_loss  fold_5@test_valid/acc  fold_5@test_valid/recall  \\\n",
       "  0                  0.565634               0.638211                  0.638211   \n",
       "  \n",
       "     fold_5@test_valid/f1  fold_5@test_valid/precision  fold_5@val/acc  \\\n",
       "  0              0.636061                     0.640083        0.653846   \n",
       "  \n",
       "     fold_5@val/recall  fold_5@val/f1  fold_5@val/precision  subject_name  \n",
       "  0           0.653846       0.654156              0.655636           S51  \n",
       "  \n",
       "  [1 rows x 110 columns],\n",
       "     mean_test/acc  mean_test/f1  mean_val/acc  mean_val/f1  \\\n",
       "  0       0.776471      0.774296      0.810169     0.809713   \n",
       "  \n",
       "     fold_1@training_roc_auc  fold_1@f1_score_Xt-2  \\\n",
       "  0                 0.930222               0.82977   \n",
       "  \n",
       "     fold_1@training_recall_score  fold_1@training_precision_score  \\\n",
       "  0                      0.863475                         0.863516   \n",
       "  \n",
       "     fold_1@training_f1_score  fold_1@f1_score-2_Xt-3  ...  \\\n",
       "  0                  0.863471                0.737392  ...   \n",
       "  \n",
       "     fold_5@training_log_loss  fold_5@test_valid/acc  fold_5@test_valid/recall  \\\n",
       "  0                  0.357144                0.79085                   0.79085   \n",
       "  \n",
       "     fold_5@test_valid/f1  fold_5@test_valid/precision  fold_5@val/acc  \\\n",
       "  0              0.788436                     0.799754        0.780142   \n",
       "  \n",
       "     fold_5@val/recall  fold_5@val/f1  fold_5@val/precision  subject_name  \n",
       "  0           0.780142       0.779677              0.783083           S52  \n",
       "  \n",
       "  [1 rows x 110 columns],\n",
       "     mean_test/acc  mean_test/f1  mean_val/acc  mean_val/f1  \\\n",
       "  0       0.921569      0.921339      0.913636     0.913594   \n",
       "  \n",
       "     fold_1@training_roc_auc  fold_1@f1_score_Xt-2  \\\n",
       "  0                 0.974366              0.895758   \n",
       "  \n",
       "     fold_1@training_recall_score  fold_1@training_precision_score  \\\n",
       "  0                      0.930314                         0.930522   \n",
       "  \n",
       "     fold_1@training_f1_score  fold_1@f1_score-2_Xt-3  ...  \\\n",
       "  0                  0.930316                0.934517  ...   \n",
       "  \n",
       "     fold_5@training_log_loss  fold_5@test_valid/acc  fold_5@test_valid/recall  \\\n",
       "  0                  0.186071               0.915033                  0.915033   \n",
       "  \n",
       "     fold_5@test_valid/f1  fold_5@test_valid/precision  fold_5@val/acc  \\\n",
       "  0              0.914814                     0.916571        0.867133   \n",
       "  \n",
       "     fold_5@val/recall  fold_5@val/f1  fold_5@val/precision  subject_name  \n",
       "  0           0.867133       0.867003              0.869001           S57  \n",
       "  \n",
       "  [1 rows x 110 columns]],\n",
       " 'riemann': [   mean_test/acc  mean_test/f1  mean_val/acc  mean_val/f1  \\\n",
       "  0       0.850216      0.849863      0.910552     0.910376   \n",
       "  \n",
       "     fold_1@training_roc_auc  fold_1@f1_score_Xt-2  \\\n",
       "  0                      1.0              0.941434   \n",
       "  \n",
       "     fold_1@training_recall_score  fold_1@training_precision_score  \\\n",
       "  0                           1.0                              1.0   \n",
       "  \n",
       "     fold_1@training_f1_score  fold_1@f1_score-2_Xt-3  ...  \\\n",
       "  0                       1.0                0.848485  ...   \n",
       "  \n",
       "     fold_5@training_log_loss  fold_5@test_valid/acc  fold_5@test_valid/recall  \\\n",
       "  0                  0.012048               0.857143                  0.857143   \n",
       "  \n",
       "     fold_5@test_valid/f1  fold_5@test_valid/precision  fold_5@val/acc  \\\n",
       "  0              0.856735                     0.868076        0.868293   \n",
       "  \n",
       "     fold_5@val/recall  fold_5@val/f1  fold_5@val/precision  subject_name  \n",
       "  0           0.868293       0.868545              0.869832           S38  \n",
       "  \n",
       "  [1 rows x 110 columns],\n",
       "     mean_test/acc  mean_test/f1  mean_val/acc  mean_val/f1  \\\n",
       "  0       0.843871      0.843395       0.93125     0.930682   \n",
       "  \n",
       "     fold_1@training_roc_auc  fold_1@f1_score_Xt-2  \\\n",
       "  0                      1.0              0.981239   \n",
       "  \n",
       "     fold_1@training_recall_score  fold_1@training_precision_score  \\\n",
       "  0                           1.0                              1.0   \n",
       "  \n",
       "     fold_1@training_f1_score  fold_1@f1_score-2_Xt-3  ...  \\\n",
       "  0                       1.0                0.851551  ...   \n",
       "  \n",
       "     fold_5@training_log_loss  fold_5@test_valid/acc  fold_5@test_valid/recall  \\\n",
       "  0                  0.000503               0.754839                  0.754839   \n",
       "  \n",
       "     fold_5@test_valid/f1  fold_5@test_valid/precision  fold_5@val/acc  \\\n",
       "  0              0.752701                      0.76711         0.81875   \n",
       "  \n",
       "     fold_5@val/recall  fold_5@val/f1  fold_5@val/precision  subject_name  \n",
       "  0            0.81875       0.816158              0.837804           S39  \n",
       "  \n",
       "  [1 rows x 110 columns],\n",
       "     mean_test/acc  mean_test/f1  mean_val/acc  mean_val/f1  \\\n",
       "  0       0.756911      0.755615      0.824786     0.824295   \n",
       "  \n",
       "     fold_1@training_roc_auc  fold_1@f1_score_Xt-2  \\\n",
       "  0                      1.0              0.961478   \n",
       "  \n",
       "     fold_1@training_recall_score  fold_1@training_precision_score  \\\n",
       "  0                           1.0                              1.0   \n",
       "  \n",
       "     fold_1@training_f1_score  fold_1@f1_score-2_Xt-3  ...  \\\n",
       "  0                       1.0                0.767659  ...   \n",
       "  \n",
       "     fold_5@training_log_loss  fold_5@test_valid/acc  fold_5@test_valid/recall  \\\n",
       "  0                  0.070004               0.756098                  0.756098   \n",
       "  \n",
       "     fold_5@test_valid/f1  fold_5@test_valid/precision  fold_5@val/acc  \\\n",
       "  0              0.756049                     0.756101        0.726496   \n",
       "  \n",
       "     fold_5@val/recall  fold_5@val/f1  fold_5@val/precision  subject_name  \n",
       "  0           0.726496       0.725284              0.726757           S51  \n",
       "  \n",
       "  [1 rows x 110 columns],\n",
       "     mean_test/acc  mean_test/f1  mean_val/acc  mean_val/f1  \\\n",
       "  0       0.871895      0.871337      0.910718      0.91055   \n",
       "  \n",
       "     fold_1@training_roc_auc  fold_1@f1_score_Xt-2  \\\n",
       "  0                      1.0              0.943483   \n",
       "  \n",
       "     fold_1@training_recall_score  fold_1@training_precision_score  \\\n",
       "  0                           1.0                              1.0   \n",
       "  \n",
       "     fold_1@training_f1_score  fold_1@f1_score-2_Xt-3  ...  \\\n",
       "  0                       1.0                0.862451  ...   \n",
       "  \n",
       "     fold_5@training_log_loss  fold_5@test_valid/acc  fold_5@test_valid/recall  \\\n",
       "  0                  0.015897               0.856209                  0.856209   \n",
       "  \n",
       "     fold_5@test_valid/f1  fold_5@test_valid/precision  fold_5@val/acc  \\\n",
       "  0              0.854106                     0.871715         0.87234   \n",
       "  \n",
       "     fold_5@val/recall  fold_5@val/f1  fold_5@val/precision  subject_name  \n",
       "  0            0.87234        0.87176              0.880101           S52  \n",
       "  \n",
       "  [1 rows x 110 columns],\n",
       "     mean_test/acc  mean_test/f1  mean_val/acc  mean_val/f1  \\\n",
       "  0       0.941176      0.941058      0.958149        0.958   \n",
       "  \n",
       "     fold_1@training_roc_auc  fold_1@f1_score_Xt-2  \\\n",
       "  0                      1.0              0.944444   \n",
       "  \n",
       "     fold_1@training_recall_score  fold_1@training_precision_score  \\\n",
       "  0                           1.0                              1.0   \n",
       "  \n",
       "     fold_1@training_f1_score  fold_1@f1_score-2_Xt-3  ...  \\\n",
       "  0                       1.0                0.947672  ...   \n",
       "  \n",
       "     fold_5@training_log_loss  fold_5@test_valid/acc  fold_5@test_valid/recall  \\\n",
       "  0                    0.0005               0.928105                  0.928105   \n",
       "  \n",
       "     fold_5@test_valid/f1  fold_5@test_valid/precision  fold_5@val/acc  \\\n",
       "  0              0.927657                     0.933795        0.888112   \n",
       "  \n",
       "     fold_5@val/recall  fold_5@val/f1  fold_5@val/precision  subject_name  \n",
       "  0           0.888112       0.887385              0.899469           S57  \n",
       "  \n",
       "  [1 rows x 110 columns]],\n",
       " 'tangent': [   mean_test/acc  mean_test/f1  mean_val/acc  mean_val/f1  \\\n",
       "  0       0.805195      0.804659      0.886289     0.886208   \n",
       "  \n",
       "     fold_1@training_roc_auc  fold_1@training_recall_score  \\\n",
       "  0                 0.991056                      0.952612   \n",
       "  \n",
       "     fold_1@training_precision_score  fold_1@training_f1_score  \\\n",
       "  0                         0.953566                  0.952682   \n",
       "  \n",
       "     fold_1@precision_score-2_Xt-2  fold_1@training_accuracy_score  ...  \\\n",
       "  0                       0.809755                        0.952612  ...   \n",
       "  \n",
       "     fold_5@training_log_loss  fold_5@test_valid/acc  fold_5@test_valid/recall  \\\n",
       "  0                  0.090537               0.857143                  0.857143   \n",
       "  \n",
       "     fold_5@test_valid/f1  fold_5@test_valid/precision  fold_5@val/acc  \\\n",
       "  0              0.856982                     0.864097        0.878049   \n",
       "  \n",
       "     fold_5@val/recall  fold_5@val/f1  fold_5@val/precision  subject_name  \n",
       "  0           0.878049       0.878372              0.879744           S38  \n",
       "  \n",
       "  [1 rows x 110 columns],\n",
       "     mean_test/acc  mean_test/f1  mean_val/acc  mean_val/f1  \\\n",
       "  0       0.846452      0.845652       0.93375     0.933579   \n",
       "  \n",
       "     fold_1@training_roc_auc  fold_1@f1_score_Xt-2  \\\n",
       "  0                 0.998369              0.981235   \n",
       "  \n",
       "     fold_1@training_recall_score  fold_1@training_precision_score  \\\n",
       "  0                         0.975                         0.975295   \n",
       "  \n",
       "     fold_1@training_f1_score  fold_1@f1_score-2_Xt-3  ...  \\\n",
       "  0                  0.974995                0.844709  ...   \n",
       "  \n",
       "     fold_5@training_log_loss  fold_5@test_valid/acc  fold_5@test_valid/recall  \\\n",
       "  0                  0.034355               0.819355                  0.819355   \n",
       "  \n",
       "     fold_5@test_valid/f1  fold_5@test_valid/precision  fold_5@val/acc  \\\n",
       "  0               0.81778                     0.834208          0.8875   \n",
       "  \n",
       "     fold_5@val/recall  fold_5@val/f1  fold_5@val/precision  subject_name  \n",
       "  0             0.8875       0.887019              0.889082           S39  \n",
       "  \n",
       "  [1 rows x 110 columns],\n",
       "     mean_test/acc  mean_test/f1  mean_val/acc  mean_val/f1  \\\n",
       "  0        0.75122      0.750995      0.817949     0.817544   \n",
       "  \n",
       "     fold_1@training_roc_auc  fold_1@f1_score_Xt-2  \\\n",
       "  0                  0.98163              0.931544   \n",
       "  \n",
       "     fold_1@training_recall_score  fold_1@training_precision_score  \\\n",
       "  0                      0.929487                         0.929984   \n",
       "  \n",
       "     fold_1@training_f1_score  fold_1@f1_score-2_Xt-3  ...  \\\n",
       "  0                  0.929528                0.760079  ...   \n",
       "  \n",
       "     fold_5@training_log_loss  fold_5@test_valid/acc  fold_5@test_valid/recall  \\\n",
       "  0                  0.140033               0.752033                  0.752033   \n",
       "  \n",
       "     fold_5@test_valid/f1  fold_5@test_valid/precision  fold_5@val/acc  \\\n",
       "  0              0.751354                     0.753706        0.696581   \n",
       "  \n",
       "     fold_5@val/recall  fold_5@val/f1  fold_5@val/precision  subject_name  \n",
       "  0           0.696581       0.696221              0.700182           S51  \n",
       "  \n",
       "  [1 rows x 110 columns],\n",
       "     mean_test/acc  mean_test/f1  mean_val/acc  mean_val/f1  \\\n",
       "  0       0.887582      0.887034      0.906493     0.905979   \n",
       "  \n",
       "     fold_1@training_roc_auc  fold_1@f1_score_Xt-2  \\\n",
       "  0                 0.998036              0.922787   \n",
       "  \n",
       "     fold_1@training_recall_score  fold_1@training_precision_score  \\\n",
       "  0                       0.98227                         0.982476   \n",
       "  \n",
       "     fold_1@training_f1_score  fold_1@f1_score-2_Xt-3  ...  \\\n",
       "  0                  0.982261                0.895362  ...   \n",
       "  \n",
       "     fold_5@training_log_loss  fold_5@test_valid/acc  fold_5@test_valid/recall  \\\n",
       "  0                  0.030415               0.862745                  0.862745   \n",
       "  \n",
       "     fold_5@test_valid/f1  fold_5@test_valid/precision  fold_5@val/acc  \\\n",
       "  0              0.860956                     0.876534        0.865248   \n",
       "  \n",
       "     fold_5@val/recall  fold_5@val/f1  fold_5@val/precision  subject_name  \n",
       "  0           0.865248       0.863636              0.877372           S52  \n",
       "  \n",
       "  [1 rows x 110 columns],\n",
       "     mean_test/acc  mean_test/f1  mean_val/acc  mean_val/f1  \\\n",
       "  0       0.924183      0.923601      0.931595     0.931369   \n",
       "  \n",
       "     fold_1@training_roc_auc  fold_1@f1_score_Xt-2  \\\n",
       "  0                      1.0              0.972244   \n",
       "  \n",
       "     fold_1@training_recall_score  fold_1@training_precision_score  \\\n",
       "  0                      0.993031                         0.993127   \n",
       "  \n",
       "     fold_1@training_f1_score  fold_1@f1_score-2_Xt-3  ...  \\\n",
       "  0                  0.993031                 0.93416  ...   \n",
       "  \n",
       "     fold_5@training_log_loss  fold_5@test_valid/acc  fold_5@test_valid/recall  \\\n",
       "  0                  0.006229               0.901961                  0.901961   \n",
       "  \n",
       "     fold_5@test_valid/f1  fold_5@test_valid/precision  fold_5@val/acc  \\\n",
       "  0              0.901547                     0.904973        0.846154   \n",
       "  \n",
       "     fold_5@val/recall  fold_5@val/f1  fold_5@val/precision  subject_name  \n",
       "  0           0.846154       0.845168              0.852641           S57  \n",
       "  \n",
       "  [1 rows x 110 columns]]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43ccee99-9aad-4355-8b78-7b353b26b4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metric(df, metric_name):\n",
    "    if 'mean_' + metric_name in df.columns:\n",
    "        return df[df['subject_name'].notna()][['subject_name', 'mean_' + metric_name]]\n",
    "    else:\n",
    "        return df[df['subject_name'].notna()]['subject_name'].apply(lambda x: x[1:-1][metric_name]).reset_index(drop=True)\n",
    "\n",
    "# Example usage\n",
    "acc_lr_data = {}\n",
    "f1_lr_data = {}\n",
    "acc_2D_data = {}\n",
    "f1_2D_data = {}\n",
    "\n",
    "# Step 3: Process the data\n",
    "for model, dfs in data_lr.items():\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    acc_lr_data[model]  = extract_metric(combined_df, 'acc').set_index('subject_name').drop_duplicates()\n",
    "    f1_lr_data[model] = extract_metric(combined_df, 'f1').set_index('subject_name').drop_duplicates()\n",
    "\n",
    "for model, dfs in data_2D.items():\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    acc_2D_data[model]  = extract_metric(combined_df, 'acc').set_index('subject_name').drop_duplicates()\n",
    "    f1_2D_data[model] = extract_metric(combined_df, 'f1').set_index('subject_name').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9700daa3-6883-4426-8d9e-5bba389a93a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test/acc</th>\n",
       "      <th>mean_test/f1</th>\n",
       "      <th>mean_val/acc</th>\n",
       "      <th>mean_val/f1</th>\n",
       "      <th>fold_1@training_roc_auc</th>\n",
       "      <th>fold_1@f1_score_Xt-2</th>\n",
       "      <th>fold_1@training_recall_score</th>\n",
       "      <th>fold_1@training_precision_score</th>\n",
       "      <th>fold_1@training_f1_score</th>\n",
       "      <th>fold_1@f1_score-2_Xt-3</th>\n",
       "      <th>...</th>\n",
       "      <th>fold_5@recall_score-2_Xt-3</th>\n",
       "      <th>fold_5@training_log_loss</th>\n",
       "      <th>fold_5@test_valid/acc</th>\n",
       "      <th>fold_5@test_valid/recall</th>\n",
       "      <th>fold_5@test_valid/f1</th>\n",
       "      <th>fold_5@test_valid/precision</th>\n",
       "      <th>fold_5@val/acc</th>\n",
       "      <th>fold_5@val/recall</th>\n",
       "      <th>fold_5@val/f1</th>\n",
       "      <th>fold_5@val/precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.924183</td>\n",
       "      <td>0.923601</td>\n",
       "      <td>0.931595</td>\n",
       "      <td>0.931369</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.972244</td>\n",
       "      <td>0.993031</td>\n",
       "      <td>0.993127</td>\n",
       "      <td>0.993031</td>\n",
       "      <td>0.93416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.006229</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.901547</td>\n",
       "      <td>0.904973</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.845168</td>\n",
       "      <td>0.852641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test/acc  mean_test/f1  mean_val/acc  mean_val/f1  \\\n",
       "0       0.924183      0.923601      0.931595     0.931369   \n",
       "\n",
       "   fold_1@training_roc_auc  fold_1@f1_score_Xt-2  \\\n",
       "0                      1.0              0.972244   \n",
       "\n",
       "   fold_1@training_recall_score  fold_1@training_precision_score  \\\n",
       "0                      0.993031                         0.993127   \n",
       "\n",
       "   fold_1@training_f1_score  fold_1@f1_score-2_Xt-3  ...  \\\n",
       "0                  0.993031                 0.93416  ...   \n",
       "\n",
       "   fold_5@recall_score-2_Xt-3  fold_5@training_log_loss  \\\n",
       "0                    0.901961                  0.006229   \n",
       "\n",
       "   fold_5@test_valid/acc  fold_5@test_valid/recall  fold_5@test_valid/f1  \\\n",
       "0               0.901961                  0.901961              0.901547   \n",
       "\n",
       "   fold_5@test_valid/precision  fold_5@val/acc  fold_5@val/recall  \\\n",
       "0                     0.904973        0.846154           0.846154   \n",
       "\n",
       "   fold_5@val/f1  fold_5@val/precision  \n",
       "0       0.845168              0.852641  \n",
       "\n",
       "[1 rows x 109 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b44a89-221e-43f0-904e-157fce6ca3d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6ad8f0fe8fecf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T11:45:34.675242600Z",
     "start_time": "2023-10-24T11:45:34.659081100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# # Step 3: Organize the metrics data\n",
    "# def extract_metric(df, metric_name):\n",
    "#     # Look for columns starting with 'val/' or 'mean_val/'\n",
    "#     relevant_columns = [col for col in df.columns if col.startswith(('val/', 'mean_val/'))]\n",
    "#     metric_columns = [col for col in relevant_columns if metric_name in col]\n",
    "#     return df[metric_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd563603d360090",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T11:45:35.090686800Z",
     "start_time": "2023-10-24T11:45:35.058816200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# def extract_metric(df, metric_name):\n",
    "#     relevant_columns = [col for col in df.columns if col.startswith(('val/', 'mean_val/'))]\n",
    "#     metric_columns = [col for col in relevant_columns if metric_name in col]\n",
    "#     return df[metric_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb07307482f28404",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "data_lr = {}\n",
    "data_2D = {}\n",
    "\n",
    "# Function to process CSV data\n",
    "def process_csv_data(csv_data):\n",
    "    # Assuming data_type1 and data_type2 are the strings containing your respective CSV data.\n",
    "\n",
    "    # For type 1\n",
    "    type1_df = pd.read_csv(pd.compat.StringIO(csv_data), header=None, names=['column'])\n",
    "\n",
    "    # Extract mean_test and mean_val columns\n",
    "    type1_df = type1_df[type1_df['column'].str.startswith(('mean_test', 'mean_val'))]\n",
    "\n",
    "    # Split column into original column name and dictionary\n",
    "    type1_df[['original_column', 'dictionary']] = type1_df['column'].str.split(',', expand=True)\n",
    "\n",
    "    # Extract values from the dictionary\n",
    "    type1_df = pd.concat([type1_df, type1_df['dictionary'].apply(lambda x: pd.Series(eval(x)))], axis=1)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    type1_df = type1_df.drop(columns=['column', 'dictionary'])\n",
    "\n",
    "    return type1_df\n",
    "\n",
    "# Step 1: Load CSV files and extract relevant information\n",
    "for csv_file in os.listdir(csv_dir):\n",
    "    if csv_file.endswith(\".csv\"):\n",
    "\n",
    "        csv_file_name = os.path.splitext(csv_file)[0]\n",
    "\n",
    "        if len(csv_file_name.split(\"_\")) == 3:\n",
    "            task, model, subject = csv_file_name.split(\"_\")\n",
    "        else:\n",
    "            task, _, model, subject = csv_file_name.split(\"_\")\n",
    "            \n",
    "        \n",
    "        \n",
    "        df = pd.read_csv(os.path.join(csv_dir, csv_file))\n",
    "        \n",
    "        if \n",
    "        \n",
    "        \n",
    "        # df.columns = df.columns.str.replace('mean_', '')  # Remove \"mean_\" prefix\n",
    "\n",
    "        # Step 2: Separate LR and 2D data\n",
    "        if task == \"LR\":\n",
    "            if model in data_lr:\n",
    "                data_lr[model].append(df.assign(subject_name=subject))\n",
    "            else:\n",
    "                data_lr[model] = [df.assign(subject_name=subject)]\n",
    "        if task == \"2D\":\n",
    "            if model in data_2D:\n",
    "                data_2D[model].append(df.assign(subject_name=subject))\n",
    "            else:\n",
    "                data_2D[model] = [df.assign(subject_name=subject)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b0c9f8a35dc890",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Process LR Data\n",
    "for model, dfs in data_lr.items():\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    combined_df = combined_df[combined_df['subject_name'].notna()]\n",
    "    acc_lr_data = combined_df.filter(like='acc').set_index('subject_name').drop_duplicates()\n",
    "    f1_lr_data = combined_df.filter(like='f1').set_index('subject_name').drop_duplicates()\n",
    "\n",
    "    # Further processing as needed\n",
    "\n",
    "# Process 2D Data\n",
    "for model, dfs in data_2D.items():\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    combined_df = combined_df[combined_df['subject_name'].notna()]\n",
    "    acc_2D_data = combined_df.filter(like='acc').set_index('subject_name').drop_duplicates()\n",
    "    f1_2D_data = combined_df.filter(like='f1').set_index('subject_name').drop_duplicates()\n",
    "\n",
    "    # Further processing as needed\n",
    "\n",
    "# Step 3: Process CSV data (assuming you have data_type1 and data_type2)\n",
    "data_type1 = \"your_csv_data_for_type1_here\"\n",
    "data_type2 = \"your_csv_data_for_type2_here\"\n",
    "\n",
    "type1_df = process_csv_data(data_type1)\n",
    "type2_df = process_csv_data(data_type2)\n",
    "\n",
    "# Renaming the columns\n",
    "type1_df = type1_df.rename(columns=lambda x: f'mean_{x}')\n",
    "type2_df = type2_df.rename(columns=lambda x: f'mean_{x}')\n",
    "\n",
    "# Combining both dataframes (if needed)\n",
    "combined_df = pd.concat([type1_df, type2_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa8431618a1ecd2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-24T12:16:12.793645800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# def extract_metric(df, metric_name):\n",
    "#     print(df)\n",
    "#     if 'mean_' + metric_name in df.columns:\n",
    "#         relevant_columns = [col for col in df.columns if col.startswith(('mean_val/'))]\n",
    "#         metric_columns = [col for col in relevant_columns if metric_name in col]\n",
    "#         return df[['subject_name'] + metric_columns]   # Include 'subject' column in the result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e4bc10dcdfe9c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T11:49:10.365533800Z",
     "start_time": "2023-10-24T11:49:10.266226700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "acc_lr_data = {}\n",
    "f1_lr_data = {}\n",
    "acc_2D_data = {}\n",
    "f1_2D_data = {}\n",
    "\n",
    "# Step 3: Process the data\n",
    "for model, dfs in data_lr.items():\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    acc_lr_data[model]  = extract_metric(combined_df, 'acc').set_index('subject_name').drop_duplicates()\n",
    "    f1_lr_data[model] = extract_metric(combined_df, 'f1').set_index('subject_name').drop_duplicates()\n",
    "    \n",
    "    \n",
    "for model, dfs in data_2D.items():\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    acc_2D_data[model]  = extract_metric(combined_df, 'acc').set_index('subject_name').drop_duplicates()\n",
    "    f1_2D_data[model] = extract_metric(combined_df, 'f1').set_index('subject_name').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6833e1fa880c83e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T11:49:11.000026100Z",
     "start_time": "2023-10-24T11:49:10.966147200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "f1_2D_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fc61c54c74f5ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T11:49:13.066316300Z",
     "start_time": "2023-10-24T11:49:13.033110400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "acc_2D_data[\"csp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46904e00bea739a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T13:09:38.370182800Z",
     "start_time": "2023-10-17T13:09:38.354568200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Assuming 'subject_name' is the column that contains subject names\n",
    "# acc_lr_data = [(model, extract_metric(pd.concat([df.assign(subject_name=subject) for model, subject, df in task_LR_data if model == model], ignore_index=True), 'acc').set_index('subject_name').drop_duplicates()) for model, _, _ in task_LR_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b91939c9ad72dd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T13:09:42.238204900Z",
     "start_time": "2023-10-17T13:09:41.793948400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming acc_lr_data is a dictionary where keys are model names and values are DataFrames\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "x_positions = np.arange(len(acc_lr_data))\n",
    "\n",
    "for i, (model, df) in enumerate(acc_lr_data.items()):\n",
    "    avg_acc = df[['val/acc']].mean(axis=1, skipna=True)\n",
    "    \n",
    "    # Adjust the x position for each boxplot\n",
    "    plt.boxplot(avg_acc.values, positions=[i])\n",
    "\n",
    "    \n",
    "plt.title('Boxplot for Model Performance LR task')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.xticks(x_positions, [model for model, _ in acc_lr_data.items()], rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f1e7c460e8272f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T13:09:46.654047900Z",
     "start_time": "2023-10-17T13:09:46.080142400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming acc_lr_data is a dictionary where keys are model names and values are DataFrames\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "x_positions = np.arange(len(acc_2D_data))\n",
    "\n",
    "for i, (model, df) in enumerate(acc_2D_data.items()):\n",
    "    avg_acc = df[['val/acc']].mean(axis=1, skipna=True)\n",
    "    \n",
    "    # Adjust the x position for each boxplot\n",
    "    plt.boxplot(avg_acc.values, positions=[i])\n",
    "\n",
    "    \n",
    "plt.title('Boxplot for Model Performance 2D task')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.xticks(x_positions, [model for model, _ in acc_2D_data.items()], rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418d498db635e976",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T13:07:37.915834800Z",
     "start_time": "2023-10-17T13:07:31.816561900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1561f581929ec47e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T13:09:55.931024700Z",
     "start_time": "2023-10-17T13:09:55.101220100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Assuming acc_lr_data is a dictionary where keys are model names and values are DataFrames\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Create lists to store subject names and average accuracies\n",
    "subject_names = []\n",
    "avg_accuracies = []\n",
    "\n",
    "# Iterate through the acc_lr_data dictionary\n",
    "for i, (model, df) in enumerate(acc_lr_data.items()):\n",
    "    avg_acc = df[['val/acc']].mean(axis=1, skipna=True)\n",
    "    \n",
    "    # Add subject names and corresponding average accuracies\n",
    "    subject_names.extend([model] * len(avg_acc))\n",
    "    avg_accuracies.extend(avg_acc)\n",
    "    \n",
    "    # Adjust the x position for each boxplot\n",
    "    plt.boxplot(avg_acc.values, positions=[i])\n",
    "\n",
    "# Add Gaussian distribution plot\n",
    "x = np.linspace(min(avg_accuracies), max(avg_accuracies), 100)\n",
    "pdf = stats.norm.pdf(x, np.mean(avg_accuracies), np.std(avg_accuracies))\n",
    "plt.plot(x, pdf, color='red')\n",
    "\n",
    "# Add subject names as dots\n",
    "plt.scatter(range(len(subject_names)), avg_accuracies, c='black', marker='o', s=10)\n",
    "\n",
    "plt.title('Model Performance')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.xticks(range(len(acc_lr_data)), [model for model, _ in acc_lr_data.items()], rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285203e21a3061e6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bbcpy_env",
   "language": "python",
   "name": "bbcpy_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
