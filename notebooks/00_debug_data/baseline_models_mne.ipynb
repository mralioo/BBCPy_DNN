{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T13:49:23.142572700Z",
     "start_time": "2023-10-28T13:49:23.108631600Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from src.data.smr_datamodule import SMR_Data\n",
    "from src.utils.device import print_data_info\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c34c4139fb8dfae5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T13:47:07.969842600Z",
     "start_time": "2023-10-28T13:46:11.838798600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Found sessions: ['Session_1', 'Session_2', 'Session_3', 'Session_4', 'Session_5', 'Session_6', 'Session_7'] for subject S5\n",
      "INFO:root:Subject S5 loading...\n",
      "INFO:root:Loading session Session_1 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noisechan [24.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Noisy channels found: [24.0], each channel will be averaged with 4 neighbors\n",
      "INFO:root:Bandpass filtering the data between 8-20 Hz\n",
      "INFO:root:Preprocessing the data ...\n",
      "INFO:root:Data shape before preprocessing: (150, 62, 12000)\n",
      "INFO:root:Data shape after preprocessing: (150, 62, 4500)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_1 (6, 62, 4500)\n",
      "run_2 (7, 62, 4500)\n",
      "run_3 (6, 62, 4500)\n",
      "run_4 (7, 62, 4500)\n",
      "run_5 (9, 62, 4500)\n",
      "run_6 (6, 62, 4500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:1/7 sessions loaded\n",
      "INFO:root:Loading session Session_2 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noisechan None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Bandpass filtering the data between 8-20 Hz\n",
      "INFO:root:Preprocessing the data ...\n",
      "INFO:root:Data shape before preprocessing: (150, 62, 12000)\n",
      "INFO:root:Data shape after preprocessing: (150, 62, 4500)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_1 (11, 62, 4500)\n",
      "run_2 (7, 62, 4500)\n",
      "run_3 (9, 62, 4500)\n",
      "run_4 (13, 62, 4500)\n",
      "run_5 (9, 62, 4500)\n",
      "run_6 (7, 62, 4500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:2/7 sessions loaded\n",
      "INFO:root:Loading session Session_3 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noisechan None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Bandpass filtering the data between 8-20 Hz\n",
      "INFO:root:Preprocessing the data ...\n",
      "INFO:root:Data shape before preprocessing: (150, 62, 12000)\n",
      "INFO:root:Data shape after preprocessing: (150, 62, 4500)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_1 (12, 62, 4500)\n",
      "run_2 (15, 62, 4500)\n",
      "run_3 (13, 62, 4500)\n",
      "run_4 (14, 62, 4500)\n",
      "run_5 (17, 62, 4500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:3/7 sessions loaded\n",
      "INFO:root:Loading session Session_4 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_6 (22, 62, 4500)\n",
      "noisechan None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Bandpass filtering the data between 8-20 Hz\n",
      "INFO:root:Preprocessing the data ...\n",
      "INFO:root:Data shape before preprocessing: (150, 62, 12000)\n",
      "INFO:root:Data shape after preprocessing: (150, 62, 4500)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_1 (13, 62, 4500)\n",
      "run_2 (12, 62, 4500)\n",
      "run_3 (15, 62, 4500)\n",
      "run_4 (11, 62, 4500)\n",
      "run_5 (12, 62, 4500)\n",
      "run_6 (15, 62, 4500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:4/7 sessions loaded\n",
      "INFO:root:Loading session Session_5 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noisechan None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Bandpass filtering the data between 8-20 Hz\n",
      "INFO:root:Preprocessing the data ...\n",
      "INFO:root:Data shape before preprocessing: (150, 62, 12000)\n",
      "INFO:root:Data shape after preprocessing: (150, 62, 4500)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_1 (15, 62, 4500)\n",
      "run_2 (6, 62, 4500)\n",
      "run_3 (21, 62, 4500)\n",
      "run_4 (20, 62, 4500)\n",
      "run_5 (18, 62, 4500)\n",
      "run_6 (14, 62, 4500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:5/7 sessions loaded\n",
      "INFO:root:Loading session Session_6 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noisechan None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Bandpass filtering the data between 8-20 Hz\n",
      "INFO:root:Preprocessing the data ...\n",
      "INFO:root:Data shape before preprocessing: (150, 62, 12000)\n",
      "INFO:root:Data shape after preprocessing: (150, 62, 4500)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_1 (15, 62, 4500)\n",
      "run_2 (7, 62, 4500)\n",
      "run_3 (11, 62, 4500)\n",
      "run_4 (18, 62, 4500)\n",
      "run_5 (12, 62, 4500)\n",
      "run_6 (8, 62, 4500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:6/7 sessions loaded\n",
      "INFO:root:Loading session Session_7 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noisechan None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Bandpass filtering the data between 8-20 Hz\n",
      "INFO:root:Preprocessing the data ...\n",
      "INFO:root:Data shape before preprocessing: (150, 62, 12000)\n",
      "INFO:root:Data shape after preprocessing: (150, 62, 4500)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_1 (20, 62, 4500)\n",
      "run_2 (22, 62, 4500)\n",
      "run_3 (20, 62, 4500)\n",
      "run_4 (22, 62, 4500)\n",
      "run_5 (25, 62, 4500)\n",
      "run_6 (19, 62, 4500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:7/7 sessions loaded\n",
      "C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\numpy\\lib\\arraysetops.py:733: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n",
      "INFO:root:Sesssion Session_7 appended, final shapes for each run:\n",
      "INFO:root:Run 1 shape: (92, 62, 4500)\n",
      "INFO:root:Run 2 shape: (76, 62, 4500)\n",
      "INFO:root:Run 3 shape: (95, 62, 4500)\n",
      "INFO:root:Run 4 shape: (105, 62, 4500)\n",
      "INFO:root:Run 5 shape: (102, 62, 4500)\n",
      "INFO:root:Run 6 shape: (91, 62, 4500)\n",
      "INFO:root:Preparing data...\n",
      "INFO:root:Train data info:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (460, 62, 4500)\n",
      "max timepoints:  130.5242172568494\n",
      "min timepoints:  -88.35799849286423\n",
      "mean timepoints:  -0.00032405977194958327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Test data info:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std timepoints:  4.307553661278638\n",
      "data shape:  (91, 62, 4500)\n",
      "max timepoints:  64.3120209590247\n",
      "min timepoints:  -66.59509069026409\n",
      "mean timepoints:  -0.0010002329798996057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Normalizing the data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std timepoints:  4.4625932339489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train data info:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (460, 62, 4500)\n",
      "max timepoints:  21.422163177147127\n",
      "min timepoints:  -21.422515888547576\n",
      "mean timepoints:  -5.723262841608256e-20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Test data info:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std timepoints:  1.0000000000000036\n",
      "data shape:  (91, 62, 4500)\n",
      "max timepoints:  62.52899999417535\n",
      "min timepoints:  -64.4336862602446\n",
      "mean timepoints:  -4.585871616426793e-05\n",
      "std timepoints:  0.9979242563508113\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path(\"D:\\\\SMR\\\\\")\n",
    "task_name = \"2D\"\n",
    "subject_sessions_dict = {\"S5\": \"all\"}\n",
    "loading_data_mode = \"within_subject\"\n",
    "ival = \"2s:11s:2ms\"\n",
    "bands = [8, 20]\n",
    "chans = \"*\"\n",
    "fallback_neighbors = 4\n",
    "transform = None\n",
    "normalize = {\"norm_type\": \"std\", \"norm_axis\": 0}\n",
    "# normalize = None\n",
    "\n",
    "process_noisy_channels = True\n",
    "ignore_noisy_sessions = False\n",
    "\n",
    "trial_type = \"valid\"\n",
    "\n",
    "smr_datamodule = SMR_Data(data_dir=data_dir,\n",
    "                          task_name=task_name,\n",
    "                          trial_type=trial_type,\n",
    "                          subject_sessions_dict=subject_sessions_dict,\n",
    "                          loading_data_mode=loading_data_mode,\n",
    "                          ival=ival,\n",
    "                          bands=bands,\n",
    "                          chans=chans,\n",
    "                          fallback_neighbors=fallback_neighbors,\n",
    "                          transform=transform,\n",
    "                          normalize=normalize,\n",
    "                          process_noisy_channels=process_noisy_channels,\n",
    "                          ignore_noisy_sessions=ignore_noisy_sessions)\n",
    "smr_datamodule.prepare_dataloader_baseline()\n",
    "train_data = smr_datamodule.train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "474568b42bc295c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T13:49:29.545181900Z",
     "start_time": "2023-10-28T13:49:27.278667700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (460, 62, 4500)\n",
      "max timepoints:  21.422163177147127\n",
      "min timepoints:  -21.422515888547576\n",
      "mean timepoints:  -5.723262841608256e-20\n",
      "std timepoints:  1.0000000000000036\n",
      "(array([0, 1, 2, 3]), array([121,  95, 121, 123], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print_data_info(train_data)\n",
    "import numpy as np\n",
    "print(np.unique(train_data.y, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fb13c7-923d-4135-8c85-ace447ef1ee4",
   "metadata": {},
   "source": [
    "## MNE data format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac99b345-5fbd-4ce0-b223-a467cf2cf6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "460 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "eeg_data = train_data.data\n",
    "# Create an events array from train_data.y and event times\n",
    "events = []\n",
    "for i, label in enumerate(train_data.y):\n",
    "    events.append([i, 0, label])\n",
    "\n",
    "# Convert the events list to a NumPy array\n",
    "events = np.array(events)\n",
    "\n",
    "info = mne.create_info(ch_names=train_data.chans, sfreq=train_data.fs, ch_types=['eeg'] * train_data.nCh)\n",
    "# Create a RawArray object\n",
    "# Create an EpochsArray object\n",
    "epochs = mne.EpochsArray(eeg_data, info, events=events, event_id = {'Left': 0, 'Right': 1, 'Up':2, 'Down':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a6ed803-bdb0-482d-b8d3-5c1147874a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_data = epochs.get_data() \n",
    "labels = epochs.events[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "237d2f07-1b24-4741-bb1c-5e73cd1b4609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(460, 62, 4500)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d587f6c3-7ce5-435e-9b83-9b8d657df4b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(460,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce5d02c-5783-4fc4-84d1-ef7f26a24283",
   "metadata": {},
   "source": [
    "## MNE CSP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b6f105b6ab075fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T14:04:36.639670500Z",
     "start_time": "2023-10-28T14:00:15.259241200Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\sklearn\\utils\\metaestimators.py:121: FutureWarning: if_delegate_has_method was deprecated in version 1.1 and will be removed in version 1.3. Use available_if instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank=None\n",
      "    Using tolerance 40 (2.2e-16 eps * 62 dim * 2.9e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 37 (2.2e-16 eps * 62 dim * 2.7e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 49 (2.2e-16 eps * 62 dim * 3.5e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 48 (2.2e-16 eps * 62 dim * 3.5e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 40 (2.2e-16 eps * 62 dim * 2.9e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 37 (2.2e-16 eps * 62 dim * 2.7e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 49 (2.2e-16 eps * 62 dim * 3.5e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 48 (2.2e-16 eps * 62 dim * 3.5e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 40 (2.2e-16 eps * 62 dim * 2.9e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 37 (2.2e-16 eps * 62 dim * 2.7e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 49 (2.2e-16 eps * 62 dim * 3.5e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 48 (2.2e-16 eps * 62 dim * 3.5e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 40 (2.2e-16 eps * 62 dim * 2.9e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 37 (2.2e-16 eps * 62 dim * 2.7e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 49 (2.2e-16 eps * 62 dim * 3.5e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 48 (2.2e-16 eps * 62 dim * 3.5e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 35 (2.2e-16 eps * 62 dim * 2.5e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 36 (2.2e-16 eps * 62 dim * 2.6e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 45 (2.2e-16 eps * 62 dim * 3.3e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 48 (2.2e-16 eps * 62 dim * 3.5e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 35 (2.2e-16 eps * 62 dim * 2.5e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 36 (2.2e-16 eps * 62 dim * 2.6e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 45 (2.2e-16 eps * 62 dim * 3.3e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 48 (2.2e-16 eps * 62 dim * 3.5e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 41 (2.2e-16 eps * 62 dim * 2.9e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 29 (2.2e-16 eps * 62 dim * 2.1e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 43 (2.2e-16 eps * 62 dim * 3.1e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 45 (2.2e-16 eps * 62 dim * 3.2e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 41 (2.2e-16 eps * 62 dim * 2.9e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 29 (2.2e-16 eps * 62 dim * 2.1e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 43 (2.2e-16 eps * 62 dim * 3.1e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 45 (2.2e-16 eps * 62 dim * 3.2e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 40 (2.2e-16 eps * 62 dim * 2.9e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 37 (2.2e-16 eps * 62 dim * 2.7e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 47 (2.2e-16 eps * 62 dim * 3.4e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 44 (2.2e-16 eps * 62 dim * 3.2e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 40 (2.2e-16 eps * 62 dim * 2.9e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 37 (2.2e-16 eps * 62 dim * 2.7e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 47 (2.2e-16 eps * 62 dim * 3.4e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 44 (2.2e-16 eps * 62 dim * 3.2e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\bbcpy\\pipeline\\pipeline.py\", line 543, in _fit_transform_one\n    Xt, yt = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\sklearn\\base.py\", line 851, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\bbcpy\\pipeline\\core.py\", line 154, in transform\n    out = self.func(x, **self.get_stdpars())\n  File \"<__array_function__ internals>\", line 200, in var\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\numpy\\core\\fromnumeric.py\", line 3747, in var\n    return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\numpy\\core\\_methods.py\", line 202, in _var\n    rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\numpy\\core\\_methods.py\", line 77, in _count_reduce_items\n    items *= arr.shape[mu.normalize_axis_index(ax, arr.ndim)]\nnumpy.AxisError: axis 2 is out of bounds for array of dimension 2\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\bbcpy\\pipeline\\pipeline.py\", line 179, in fit\n    Xt, yt = self._fit(X, y, **fit_params_steps)\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\bbcpy\\pipeline\\pipeline.py\", line 146, in _fit\n    X, y, fitted_transformer = fit_transform_one_cached(\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\joblib\\memory.py\", line 353, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\bbcpy\\pipeline\\pipeline.py\", line 545, in _fit_transform_one\n    Xt = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\sklearn\\base.py\", line 851, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\bbcpy\\pipeline\\core.py\", line 154, in transform\n    out = self.func(x, **self.get_stdpars())\n  File \"<__array_function__ internals>\", line 200, in var\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\numpy\\core\\fromnumeric.py\", line 3747, in var\n    return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\numpy\\core\\_methods.py\", line 202, in _var\n    rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\numpy\\core\\_methods.py\", line 77, in _count_reduce_items\n    items *= arr.shape[mu.normalize_axis_index(ax, arr.ndim)]\nnumpy.AxisError: axis 2 is out of bounds for array of dimension 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 51\u001b[0m\n\u001b[0;32m     43\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     45\u001b[0m clf \u001b[38;5;241m=\u001b[39m  make_pipeline(\n\u001b[0;32m     46\u001b[0m         csp,\n\u001b[0;32m     47\u001b[0m         var,\n\u001b[0;32m     48\u001b[0m         np\u001b[38;5;241m.\u001b[39mlog,\n\u001b[0;32m     49\u001b[0m         LDA()\n\u001b[0;32m     50\u001b[0m     )\n\u001b[1;32m---> 51\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:285\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m    266\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[1;32m--> 285\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "File \u001b[1;32m~\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\bbcpy\\pipeline\\pipeline.py\", line 543, in _fit_transform_one\n    Xt, yt = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\sklearn\\base.py\", line 851, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\bbcpy\\pipeline\\core.py\", line 154, in transform\n    out = self.func(x, **self.get_stdpars())\n  File \"<__array_function__ internals>\", line 200, in var\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\numpy\\core\\fromnumeric.py\", line 3747, in var\n    return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\numpy\\core\\_methods.py\", line 202, in _var\n    rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\numpy\\core\\_methods.py\", line 77, in _count_reduce_items\n    items *= arr.shape[mu.normalize_axis_index(ax, arr.ndim)]\nnumpy.AxisError: axis 2 is out of bounds for array of dimension 2\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\bbcpy\\pipeline\\pipeline.py\", line 179, in fit\n    Xt, yt = self._fit(X, y, **fit_params_steps)\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\bbcpy\\pipeline\\pipeline.py\", line 146, in _fit\n    X, y, fitted_transformer = fit_transform_one_cached(\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\joblib\\memory.py\", line 353, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\bbcpy\\pipeline\\pipeline.py\", line 545, in _fit_transform_one\n    Xt = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\sklearn\\base.py\", line 851, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\bbcpy\\pipeline\\core.py\", line 154, in transform\n    out = self.func(x, **self.get_stdpars())\n  File \"<__array_function__ internals>\", line 200, in var\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\numpy\\core\\fromnumeric.py\", line 3747, in var\n    return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\numpy\\core\\_methods.py\", line 202, in _var\n    rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)\n  File \"C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\numpy\\core\\_methods.py\", line 77, in _count_reduce_items\n    items *= arr.shape[mu.normalize_axis_index(ax, arr.ndim)]\nnumpy.AxisError: axis 2 is out of bounds for array of dimension 2\n"
     ]
    }
   ],
   "source": [
    "from mne.decoding import CSP\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import bbcpy.functions.helpers as helpers\n",
    "from bbcpy.functions.base import ImportFunc\n",
    "from bbcpy.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Define the number of splits for cross-validation\n",
    "n_splits = 5\n",
    "# Define the cross-validator\n",
    "cv = KFold(n_splits=n_splits, shuffle=False)\n",
    "\n",
    "# Assemble a classifier\n",
    "var = ImportFunc(np.var, axis=2)\n",
    "\n",
    "# MNE csp \n",
    "n_components=8\n",
    "reg=0.2 #float | str | None (default None)allow regularization for covariance estimation|If float (between 0 and 1), shrinkage is used/\n",
    "log=False  # None | bool (default None)\n",
    "cov_est='concat' #concat | epoch (default concat)\n",
    "transform_into='average_power' #average_power : the average power of each spatial filter| csp_space :  the data in CSP space(default average_power)\n",
    "norm_trace=True # bool (default False) Normalize class covariance by its trace.\n",
    "cov_method_params=None #dict | None Parameters to pass to mne.compute_covariance().\n",
    "rank=None #None | info | full | dict\n",
    "component_order='mutual_info' #mutual_info | alternate (default mutual_info) \n",
    "\n",
    "csp = CSP(n_components=n_components,\n",
    "          reg=reg,\n",
    "          log=log,\n",
    "          cov_est=cov_est,\n",
    "          transform_into=transform_into,\n",
    "          norm_trace=norm_trace,\n",
    "          cov_method_params=cov_method_params,\n",
    "          rank=rank,\n",
    "          component_order=component_order)\n",
    "\n",
    "results = []\n",
    "\n",
    "clf =  make_pipeline(\n",
    "        csp,\n",
    "        var,\n",
    "        np.log,\n",
    "        LDA()\n",
    "    )\n",
    "scores = cross_val_score(clf, epochs_data,labels, cv=cv, n_jobs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2115c8ef-58df-4c4f-8e71-4b6140572f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "# Store results for each fold\n",
    "for i, score in enumerate(scores):\n",
    "    results.append([i+1, score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "837675f6-9c6e-47d6-8b8e-eb3ab9fd76d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0.5217391304347826],\n",
       " [2, 0.5217391304347826],\n",
       " [3, 0.40217391304347827],\n",
       " [4, 0.4891304347826087],\n",
       " [5, 0.40217391304347827]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5aaa5039-2620-43dd-b101-0c8c3dc4390c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0.9876543209876543],\n",
       " [2, 0.9876543209876543],\n",
       " [3, 0.9629629629629629],\n",
       " [4, 0.9382716049382716],\n",
       " [5, 0.8518518518518519]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e1a25b-3c21-4593-a58c-f9543ec7df0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_path = \"./LR_results_MNE/run_3/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b512fb9faeba23",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame from the results\n",
    "subject_name = list(subject_sessions_dict.keys())[0]\n",
    "results_df = pd.DataFrame(results, columns=['fold', 'score'])\n",
    "file_name = f'{subject_name}_results_csp_mne.csv'\n",
    "results_df.to_csv(file_name, index=False)\n",
    "\n",
    "# Calculate mean and standard deviation for each excllev value\n",
    "summary_df = results_df.groupby('fold')[['score']].agg(['mean', 'std'])\n",
    "file_name = f'{subject_name}_summary_csp_mne.csv'\n",
    "summary_df.to_csv(file_name)\n",
    "\n",
    "# Print the results\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c7328c66d6f47d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "epoch_data = train_data\n",
    "labels = train_data.y\n",
    "epoch_data_info = mne.create_info(train_data.chans, train_data.fs, ch_types='eeg', verbose=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12946e5-fe7e-4825-bb01-538656fbc2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_data_info.set_montage(epochs.get_montage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767b9c66-b421-457d-a1f9-cf7ee289368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot CSP patterns estimated on full data for visualization\n",
    "csp.fit_transform(epoch_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8903f64-0032-4ba2-9208-132f422be701",
   "metadata": {},
   "outputs": [],
   "source": [
    "csp.patterns_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21178e3-f2b1-4392-9f23-80f3d7cfeecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "csp.filters_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2024ffcc-7a7a-40da-b9bb-f24dedccd701",
   "metadata": {},
   "outputs": [],
   "source": [
    "csp.plot_patterns(info=epoch_data_info,\n",
    "                  average=0.1,\n",
    "                  ch_type=\"eeg\",\n",
    "                  units=\"Patterns (AU)\", \n",
    "                  size=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3519d7-9ed6-4d19-bdb9-8a8135022f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
