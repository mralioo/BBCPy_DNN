{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T13:12:18.666221900Z",
     "start_time": "2023-10-28T13:12:06.400471600Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.data.smr_datamodule import SMR_Data\n",
    "from src.utils.device import print_data_info\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf551638b85f3d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T13:13:13.443952900Z",
     "start_time": "2023-10-28T13:12:18.681820300Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = Path(\"D:\\\\SMR\\\\\")\n",
    "task_name = \"2D\"\n",
    "subject_sessions_dict = {\"S5\": \"all\"}\n",
    "loading_data_mode = \"within_subject\"\n",
    "ival = \"2s:11s:1ms\"\n",
    "bands = [8, 20]\n",
    "chans = \"*\"\n",
    "fallback_neighbors = 4\n",
    "transform = None\n",
    "normalize = {\"norm_type\": \"std\", \"norm_axis\": 0}\n",
    "# normalize = None\n",
    "process_noisy_channels = True\n",
    "ignore_noisy_sessions = False\n",
    "\n",
    "trial_type = \"forced\"\n",
    "\n",
    "smr_datamodule = SMR_Data(data_dir=data_dir,\n",
    "                          task_name=task_name,\n",
    "                          trial_type=trial_type,\n",
    "                          subject_sessions_dict=subject_sessions_dict,\n",
    "                          loading_data_mode=loading_data_mode,\n",
    "                          ival=ival,\n",
    "                          bands=bands,\n",
    "                          chans=chans,\n",
    "                          fallback_neighbors=fallback_neighbors,\n",
    "                          transform=transform,\n",
    "                          normalize=normalize,\n",
    "                          process_noisy_channels=process_noisy_channels,\n",
    "                          ignore_noisy_sessions=ignore_noisy_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca809e0-f3cc-49a7-98f6-ab2ece46fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "smr_datamodule.prepare_dataloader_baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce05730c-4a82-4598-8780-5fca928ab28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = smr_datamodule.train_data\n",
    "print_data_info(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ae9cbff15dc2d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T13:13:50.370560500Z",
     "start_time": "2023-10-28T13:13:47.928355200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "np.unique(train_data.y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c38d72-4044-4558-97d0-7ae852ba31a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "# enumerate the splits and summarize the distributions\n",
    "for train_ix, test_ix in kfold.split(train_data, train_data.y):\n",
    " # select rows\n",
    " train_X, test_X = train_data[train_ix], train_data[test_ix]\n",
    " train_y, test_y = train_data.y[train_ix], train_data.y[test_ix]\n",
    " # summarize train and test composition\n",
    " train_0, train_1, train_2, train_3 = len(train_y[train_y==0]), len(train_y[train_y==1]), len(train_y[train_y==2]), len(train_y[train_y==3])\n",
    " test_0, test_1, test_2, test_3 = len(test_y[test_y==0]), len(test_y[test_y==1]), len(test_y[test_y==2]), len(test_y[test_y==3])\n",
    " print('>Train: 0=%d, 1=%d,2=%d, 3=%d, Test: 0=%d, 1=%d, 2=%d, 3=%d' % (train_0, train_1,train_2, train_3, test_0, test_1,test_2, test_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55310b4-74f7-4c8b-95ab-7011d2563ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_data.y), y=train_data.y)\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "class_weights_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc839292-15ee-4b4c-bd03-9f059ba43197",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_path = \"../results_csv/2D_results_filters/run_3/\"\n",
    "os.makedirs(run_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa347af1-433b-4322-a67f-8629233b3689",
   "metadata": {},
   "source": [
    "### Cross Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47b021c-71c0-4573-ab68-e9d357acec9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9e69ede301a3eb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## BBCpy toolbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e45ef80-94d8-4db6-81d2-67ff50c44684",
   "metadata": {},
   "source": [
    "### CSP MNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af9741b-d112-4ffe-b473-1134bbcf36fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bbcpy.pipeline import make_pipeline\n",
    "import bbcpy.functions.helpers as helpers\n",
    "from bbcpy.functions.base import ImportFunc\n",
    "from mne.decoding import CSP\n",
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "var = ImportFunc(np.var, axis=2)\n",
    "# MNE csp \n",
    "n_components=[4 ,6, 8, 10]\n",
    "reg=0.2 #float | str | None (default None)allow regularization for covariance estimation|If float (between 0 and 1), shrinkage is used/\n",
    "log=False  # None | bool (default None)\n",
    "cov_est='concat' #‘concat’ | ‘epoch’ (default ‘concat’)\n",
    "transform_into='average_power' #‘average_power’ : the average power of each spatial filter| ‘csp_space’ :  the data in CSP space(default ‘average_power’)\n",
    "norm_trace=True # bool (default False) Normalize class covariance by its trace.\n",
    "cov_method_params=None #dict | None Parameters to pass to mne.compute_covariance().\n",
    "rank=None #None | ‘info’ | ‘full’ | dict\n",
    "component_order='mutual_info' #‘mutual_info’ | ‘alternate’ (default ‘mutual_info’) \n",
    "\n",
    "results = []\n",
    "for filter in n_components:\n",
    "    csp = CSP(n_components=filter,\n",
    "              reg=reg,\n",
    "              log=log,\n",
    "              cov_est=cov_est,\n",
    "              transform_into=transform_into,\n",
    "              norm_trace=norm_trace,\n",
    "              cov_method_params=cov_method_params,\n",
    "              rank=rank,\n",
    "              component_order=component_order)\n",
    "    \n",
    "    csp_pipeline = make_pipeline(   csp,\n",
    "                                    var,\n",
    "                                    np.log,\n",
    "                                    LDA()\n",
    "                                )\n",
    "    \n",
    "    # Perform cross-validation and store the results\n",
    "    scores = cross_val_score(csp_pipeline, train_data, train_data.y, cv=cv, error_score='raise')\n",
    "\n",
    "    # Store results for each fold\n",
    "    for i, score in enumerate(scores):\n",
    "        results.append([filter, i+1, score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaa2be5-0fa6-47d1-b593-ed3a96245c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the results\n",
    "file_name = 'filter_results_csp_MNE.csv'\n",
    "results_df = pd.DataFrame(results, columns = ['filter', 'fold', 'score'])\n",
    "results_df.to_csv(os.path.join(run_path, file_name), index=False)\n",
    "\n",
    "# Calculate mean and standard deviation for each excllev value\n",
    "summary_df = results_df.groupby('filter')[['score']].agg(['mean', 'std'])\n",
    "summary_df\n",
    "file_name = 'filter_summary_csp_MNE.csv'\n",
    "summary_df.to_csv(os.path.join(run_path, file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f7c4d2-1eac-44bc-8983-41453777f3b5",
   "metadata": {},
   "source": [
    "## Riemann "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3c8ea7453a8fc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T13:13:56.327175500Z",
     "start_time": "2023-10-28T13:13:56.264651400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pyriemann\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import bbcpy\n",
    "from bbcpy.functions.artireject import AverageVariance\n",
    "from bbcpy.pipeline import make_pipeline\n",
    "from bbcpy.functions.base import ImportFunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f1491bbb6f95b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T13:18:32.104358200Z",
     "start_time": "2023-10-28T13:16:57.368260200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the values of excllev to investigate\n",
    "excllev_values = [None, 1.2, 1.8, 2, 4, 8, 10, 20, 100]\n",
    "estimator = 'lwf'\n",
    "# Initialize an empty list to store results\n",
    "results = []\n",
    "\n",
    "for excllev in excllev_values:\n",
    "    # AverageVariance(excllev=filter, estimator=estimator)\n",
    "    Cov = ImportFunc(bbcpy.functions.statistics.cov, estimator=estimator)\n",
    "    riemann_pipeline = make_pipeline(AverageVariance(excllev=excllev, estimator=estimator),\n",
    "                                     Cov,\n",
    "                                     pyriemann.classification.SVC(metric='riemann', class_weight=class_weights_dict, decision_function_shape=\"ovo\"))\n",
    "    # Perform cross-validation and store the results\n",
    "    scores = cross_val_score(riemann_pipeline, train_data, train_data.y, cv=cv, error_score='raise')\n",
    "   \n",
    "    # Store results for each fold\n",
    "    for i, score in enumerate(scores):\n",
    "        results.append([excllev, i+1, score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f788b3e733685c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T13:16:25.851176600Z",
     "start_time": "2023-10-28T13:14:01.570688300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results, columns=['excllev', 'fold', 'score'])\n",
    "file_name = 'excllev_results_Riemann_bbcpy.csv'\n",
    "results_df.to_csv(os.path.join(run_path, file_name), index=False)\n",
    "\n",
    "# Calculate mean and standard deviation for each excllev value\n",
    "summary_df = results_df.groupby('excllev')[['score']].agg(['mean', 'std'])\n",
    "summary_df\n",
    "file_name = 'excllev_summary_Riemann_bbcpy.csv'\n",
    "summary_df.to_csv(os.path.join(run_path, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626901f5-d05f-4803-bd08-d761eaa47ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475bb7b3-5330-4b10-a996-d66f6a7ac0bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T13:20:57.565367900Z",
     "start_time": "2023-10-28T13:18:32.104358200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Tangent Rieamnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece2a6cc-86f9-43bb-bbb9-41ad5678dd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the values of excllev to investigate\n",
    "excllev_values = [None, 1.2, 1.8, 2, 4, 8, 10, 20, 100]\n",
    "estimator = 'lwf'\n",
    "# Initialize an empty list to store results\n",
    "results = []\n",
    "for excllev in excllev_values:\n",
    "\n",
    "    Triemann_pipeline = make_pipeline(AverageVariance(excllev=excllev, estimator=estimator),\n",
    "                                      ImportFunc(bbcpy.functions.statistics.cov, estimator=estimator),\n",
    "                                      pyriemann.tangentspace.TangentSpace(),\n",
    "                                      sklearn.svm.SVC(class_weight=class_weights_dict, decision_function_shape=\"ovo\"))\n",
    "    # Perform cross-validation and store the results\n",
    "    scores = cross_val_score(Triemann_pipeline, train_data, train_data.y, cv=cv, error_score='raise')\n",
    "    \n",
    "    # Store results for each fold\n",
    "    for i, score in enumerate(scores):\n",
    "        results.append([excllev, i+1, score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca29640-e508-4b23-b7fa-4e38138db70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results, columns=['excllev', 'fold', 'score'])\n",
    "file_name = 'excllev_results_TRiemann_bbcpy.csv'\n",
    "results_df.to_csv(os.path.join(run_path, file_name), index=False)\n",
    "\n",
    "# Calculate mean and standard deviation for each excllev value\n",
    "summary_df = results_df.groupby('excllev')[['score']].agg(['mean', 'std'])\n",
    "summary_df\n",
    "file_name = 'excllev_summary_TRiemann_bbcpy.csv'\n",
    "summary_df.to_csv(os.path.join(run_path, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60c3d99-8998-4625-a4da-ce36d560da0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd07597f-2194-4180-acf3-ac7dc67ddce4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
