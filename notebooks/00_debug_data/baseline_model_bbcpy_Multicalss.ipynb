{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T13:12:18.666221900Z",
     "start_time": "2023-10-28T13:12:06.400471600Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.data.smr_datamodule import SMR_Data\n",
    "from src.utils.device import print_data_info\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bf551638b85f3d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T13:13:13.443952900Z",
     "start_time": "2023-10-28T13:12:18.681820300Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = Path(\"D:\\\\SMR\\\\\")\n",
    "task_name = \"2D\"\n",
    "subject_sessions_dict = {\"S5\": \"all\"}\n",
    "loading_data_mode = \"within_subject\"\n",
    "ival = \"2s:11s:1ms\"\n",
    "bands = [8, 20]\n",
    "chans = \"*\"\n",
    "fallback_neighbors = 4\n",
    "transform = None\n",
    "normalize = {\"norm_type\": \"std\", \"norm_axis\": 0}\n",
    "# normalize = None\n",
    "process_noisy_channels = True\n",
    "ignore_noisy_sessions = False\n",
    "\n",
    "trial_type = \"forced\"\n",
    "\n",
    "smr_datamodule = SMR_Data(data_dir=data_dir,\n",
    "                          task_name=task_name,\n",
    "                          trial_type=trial_type,\n",
    "                          subject_sessions_dict=subject_sessions_dict,\n",
    "                          loading_data_mode=loading_data_mode,\n",
    "                          ival=ival,\n",
    "                          bands=bands,\n",
    "                          chans=chans,\n",
    "                          fallback_neighbors=fallback_neighbors,\n",
    "                          transform=transform,\n",
    "                          normalize=normalize,\n",
    "                          process_noisy_channels=process_noisy_channels,\n",
    "                          ignore_noisy_sessions=ignore_noisy_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ca809e0-f3cc-49a7-98f6-ab2ece46fe3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Found sessions: ['Session_1', 'Session_2', 'Session_3', 'Session_4', 'Session_5', 'Session_6', 'Session_7'] for subject S5\n",
      "INFO:root:Subject S5 loading...\n",
      "INFO:root:Loading session Session_1 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noisechan [24.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Noisy channels found: [24.0], each channel will be averaged with 4 neighbors\n",
      "INFO:root:Bandpass filtering the data between 8-20 Hz\n",
      "INFO:root:Preprocessing the data ...\n",
      "INFO:root:Data shape before preprocessing: (150, 62, 12000)\n",
      "INFO:root:Data shape after preprocessing: (150, 62, 9000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_1 (6, 62, 9000)\n",
      "run_2 (8, 62, 9000)\n",
      "run_3 (6, 62, 9000)\n",
      "run_4 (8, 62, 9000)\n",
      "run_5 (9, 62, 9000)\n",
      "run_6 (6, 62, 9000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:1/7 sessions loaded\n",
      "INFO:root:Loading session Session_2 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noisechan None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Bandpass filtering the data between 8-20 Hz\n",
      "INFO:root:Preprocessing the data ...\n",
      "INFO:root:Data shape before preprocessing: (150, 62, 12000)\n",
      "INFO:root:Data shape after preprocessing: (150, 62, 9000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_1 (11, 62, 9000)\n",
      "run_2 (7, 62, 9000)\n",
      "run_3 (11, 62, 9000)\n",
      "run_4 (13, 62, 9000)\n",
      "run_5 (9, 62, 9000)\n",
      "run_6 (7, 62, 9000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:2/7 sessions loaded\n",
      "INFO:root:Loading session Session_3 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noisechan None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Bandpass filtering the data between 8-20 Hz\n",
      "INFO:root:Preprocessing the data ...\n",
      "INFO:root:Data shape before preprocessing: (150, 62, 12000)\n",
      "INFO:root:Data shape after preprocessing: (150, 62, 9000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_1 (12, 62, 9000)\n",
      "run_2 (15, 62, 9000)\n",
      "run_3 (13, 62, 9000)\n",
      "run_4 (15, 62, 9000)\n",
      "run_5 (17, 62, 9000)\n",
      "run_6 (22, 62, 9000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:3/7 sessions loaded\n",
      "INFO:root:Loading session Session_4 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noisechan None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Bandpass filtering the data between 8-20 Hz\n",
      "INFO:root:Preprocessing the data ...\n",
      "INFO:root:Data shape before preprocessing: (150, 62, 12000)\n",
      "INFO:root:Data shape after preprocessing: (150, 62, 9000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_1 (13, 62, 9000)\n",
      "run_2 (12, 62, 9000)\n",
      "run_3 (15, 62, 9000)\n",
      "run_4 (11, 62, 9000)\n",
      "run_5 (12, 62, 9000)\n",
      "run_6 (15, 62, 9000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:4/7 sessions loaded\n",
      "INFO:root:Loading session Session_5 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noisechan None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Bandpass filtering the data between 8-20 Hz\n",
      "INFO:root:Preprocessing the data ...\n",
      "INFO:root:Data shape before preprocessing: (150, 62, 12000)\n",
      "INFO:root:Data shape after preprocessing: (150, 62, 9000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_1 (15, 62, 9000)\n",
      "run_2 (7, 62, 9000)\n",
      "run_3 (21, 62, 9000)\n",
      "run_4 (20, 62, 9000)\n",
      "run_5 (18, 62, 9000)\n",
      "run_6 (14, 62, 9000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:5/7 sessions loaded\n",
      "INFO:root:Loading session Session_6 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noisechan None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Bandpass filtering the data between 8-20 Hz\n",
      "INFO:root:Preprocessing the data ...\n",
      "INFO:root:Data shape before preprocessing: (150, 62, 12000)\n",
      "INFO:root:Data shape after preprocessing: (150, 62, 9000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_1 (15, 62, 9000)\n",
      "run_2 (8, 62, 9000)\n",
      "run_3 (11, 62, 9000)\n",
      "run_4 (18, 62, 9000)\n",
      "run_5 (12, 62, 9000)\n",
      "run_6 (8, 62, 9000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:6/7 sessions loaded\n",
      "INFO:root:Loading session Session_7 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noisechan None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Bandpass filtering the data between 8-20 Hz\n",
      "INFO:root:Preprocessing the data ...\n",
      "INFO:root:Data shape before preprocessing: (150, 62, 12000)\n",
      "INFO:root:Data shape after preprocessing: (150, 62, 9000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_1 (20, 62, 9000)\n",
      "run_2 (22, 62, 9000)\n",
      "run_3 (20, 62, 9000)\n",
      "run_4 (22, 62, 9000)\n",
      "run_5 (25, 62, 9000)\n",
      "run_6 (19, 62, 9000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:7/7 sessions loaded\n",
      "C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\numpy\\lib\\arraysetops.py:733: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n",
      "INFO:root:Sesssion Session_7 appended, final shapes for each run:\n",
      "INFO:root:Run 1 shape: (92, 62, 9000)\n",
      "INFO:root:Run 2 shape: (79, 62, 9000)\n",
      "INFO:root:Run 3 shape: (97, 62, 9000)\n",
      "INFO:root:Run 4 shape: (107, 62, 9000)\n",
      "INFO:root:Run 5 shape: (102, 62, 9000)\n",
      "INFO:root:Run 6 shape: (91, 62, 9000)\n",
      "INFO:root:Preparing data...\n",
      "INFO:root:Train data info:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (467, 62, 9000)\n",
      "max timepoints:  130.53390629644787\n",
      "min timepoints:  -88.3748917052867\n",
      "mean timepoints:  -0.000317594153439151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Test data info:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std timepoints:  4.323102449186794\n",
      "data shape:  (91, 62, 9000)\n",
      "max timepoints:  64.3120209590247\n",
      "min timepoints:  -66.59509069026409\n",
      "mean timepoints:  -0.0010250158050268642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Normalizing the data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std timepoints:  4.4622604820023035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train data info:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (467, 62, 9000)\n",
      "max timepoints:  21.18550147428548\n",
      "min timepoints:  -21.01730135666379\n",
      "mean timepoints:  -1.1839379547137434e-19\n",
      "std timepoints:  1.0000000000000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Test data info:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (91, 62, 9000)\n",
      "max timepoints:  44.442769018454484\n",
      "min timepoints:  -51.06200604503875\n",
      "mean timepoints:  -0.00015597884131248827\n",
      "std timepoints:  0.9744743880239489\n"
     ]
    }
   ],
   "source": [
    "smr_datamodule.prepare_dataloader_baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce05730c-4a82-4598-8780-5fca928ab28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (467, 62, 9000)\n",
      "max timepoints:  21.18550147428548\n",
      "min timepoints:  -21.01730135666379\n",
      "mean timepoints:  -1.1839379547137434e-19\n",
      "std timepoints:  1.0000000000000004\n"
     ]
    }
   ],
   "source": [
    "train_data = smr_datamodule.train_data\n",
    "print_data_info(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5ae9cbff15dc2d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T13:13:50.370560500Z",
     "start_time": "2023-10-28T13:13:47.928355200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3]), array([122,  95, 127, 123], dtype=int64))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_data.y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9eb1eea-d5ee-455f-ae10-814d167a96eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, 0, 1, 0, 3, 1, 3, 3, 0, 0, 1, 2, 2, 1, 3, 1, 3, 2, 3, 0,\n",
       "       3, 0, 3, 2, 3, 0, 1, 0, 3, 2, 3, 1, 0, 3, 2, 2, 0, 1, 3, 3, 0, 2,\n",
       "       3, 0, 2, 3, 1, 2, 3, 1, 2, 0, 3, 0, 1, 1, 3, 2, 1, 3, 2, 3, 1, 0,\n",
       "       0, 2, 2, 0, 2, 0, 3, 1, 0, 3, 2, 0, 2, 3, 2, 0, 3, 1, 2, 3, 1, 0,\n",
       "       2, 3, 0, 1, 2, 0, 0, 0, 1, 0, 3, 1, 3, 3, 0, 0, 1, 2, 2, 1, 3, 1,\n",
       "       3, 2, 3, 0, 3, 0, 3, 2, 3, 0, 1, 0, 3, 2, 3, 1, 0, 3, 2, 2, 0, 1,\n",
       "       3, 3, 0, 2, 3, 0, 2, 3, 1, 2, 3, 1, 2, 0, 3, 0, 1, 1, 3, 2, 1, 3,\n",
       "       2, 3, 1, 0, 0, 2, 2, 0, 2, 0, 3, 1, 0, 3, 2, 0, 2, 3, 2, 0, 3, 1,\n",
       "       2, 3, 1, 0, 2, 3, 0, 1, 2, 1, 0, 0, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2,\n",
       "       1, 1, 3, 1, 0, 0, 1, 2, 0, 3, 2, 1, 2, 1, 0, 1, 2, 1, 3, 0, 2, 3,\n",
       "       0, 1, 3, 1, 3, 0, 2, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 2,\n",
       "       3, 0, 2, 3, 0, 2, 3, 0, 1, 2, 3, 0, 3, 1, 2, 1, 0, 3, 2, 0, 2, 0,\n",
       "       1, 0, 2, 1, 2, 1, 0, 3, 1, 0, 3, 2, 1, 2, 1, 3, 3, 1, 3, 3, 3, 2,\n",
       "       0, 3, 0, 1, 2, 2, 0, 0, 2, 1, 3, 0, 2, 2, 1, 3, 2, 2, 1, 3, 2, 2,\n",
       "       2, 1, 3, 2, 0, 1, 3, 1, 0, 2, 1, 2, 1, 0, 3, 2, 0, 3, 1, 2, 0, 0,\n",
       "       0, 2, 2, 2, 2, 3, 1, 0, 2, 2, 3, 1, 1, 3, 0, 3, 1, 2, 0, 2, 2, 0,\n",
       "       3, 0, 3, 1, 2, 1, 3, 2, 2, 0, 2, 0, 2, 1, 2, 0, 3, 1, 0, 2, 3, 1,\n",
       "       3, 3, 3, 2, 0, 2, 3, 3, 2, 0, 1, 3, 0, 3, 3, 0, 3, 1, 3, 0, 2, 2,\n",
       "       3, 3, 3, 2, 2, 0, 1, 3, 2, 0, 3, 3, 1, 0, 2, 3, 1, 3, 2, 1, 0, 3,\n",
       "       2, 0, 2, 3, 3, 1, 2, 0, 2, 1, 3, 2, 0, 3, 3, 1, 2, 3, 0, 1, 3, 2,\n",
       "       3, 2, 0, 1, 1, 2, 3, 1, 0, 3, 1, 2, 2, 3, 0, 1, 2, 0, 1, 3, 3, 2,\n",
       "       0, 1, 3, 0, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efb0cfdd-0623-4e1e-8868-261389f95122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(467, 62, 9000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c862c0bf-5cd4-4991-b303-a06bbadef5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data to npz \n",
    "data = np.array(train_data)\n",
    "labels = train_data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5b0156d-c209-4d61-b5ed-3e983ad05132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving data and labels\n",
    "np.savez_compressed('smr_sample_S5.npz', data_array=data, label_array=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10efccd5-43fa-44d8-a983-1086a16cdcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data and labels\n",
    "loaded = np.load('smr_sample_S5.npz')\n",
    "loaded_data = loaded['data_array']\n",
    "loaded_labels = loaded['label_array']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d258bc67-f82d-4818-9a8c-1ab8cde7fcfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(467, 62, 9000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "977880bf-a44f-43a5-a487-d4231494eeb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(467,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66d62d8f-e06d-4167-8481-e6b48adff0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03c38d72-4044-4558-97d0-7ae852ba31a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Train: 0=98, 1=76,2=101, 3=98, Test: 0=24, 1=19, 2=26, 3=25\n",
      ">Train: 0=98, 1=76,2=101, 3=98, Test: 0=24, 1=19, 2=26, 3=25\n",
      ">Train: 0=97, 1=76,2=102, 3=99, Test: 0=25, 1=19, 2=25, 3=24\n",
      ">Train: 0=97, 1=76,2=102, 3=99, Test: 0=25, 1=19, 2=25, 3=24\n",
      ">Train: 0=98, 1=76,2=102, 3=98, Test: 0=24, 1=19, 2=25, 3=25\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "# enumerate the splits and summarize the distributions\n",
    "for train_ix, test_ix in kfold.split(train_data, train_data.y):\n",
    " # select rows\n",
    " train_X, test_X = train_data[train_ix], train_data[test_ix]\n",
    " train_y, test_y = train_data.y[train_ix], train_data.y[test_ix]\n",
    " # summarize train and test composition\n",
    " train_0, train_1, train_2, train_3 = len(train_y[train_y==0]), len(train_y[train_y==1]), len(train_y[train_y==2]), len(train_y[train_y==3])\n",
    " test_0, test_1, test_2, test_3 = len(test_y[test_y==0]), len(test_y[test_y==1]), len(test_y[test_y==2]), len(test_y[test_y==3])\n",
    " print('>Train: 0=%d, 1=%d,2=%d, 3=%d, Test: 0=%d, 1=%d, 2=%d, 3=%d' % (train_0, train_1,train_2, train_3, test_0, test_1,test_2, test_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a55310b4-74f7-4c8b-95ab-7011d2563ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.9569672131147541,\n",
       " 1: 1.2289473684210526,\n",
       " 2: 0.9192913385826772,\n",
       " 3: 0.9491869918699187}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_data.y), y=train_data.y)\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "class_weights_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc839292-15ee-4b4c-bd03-9f059ba43197",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_path = \"../results_csv/2D_results_filters/run_3/\"\n",
    "os.makedirs(run_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa347af1-433b-4322-a67f-8629233b3689",
   "metadata": {},
   "source": [
    "### Cross Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a47b021c-71c0-4573-ab68-e9d357acec9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9e69ede301a3eb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## BBCpy toolbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e45ef80-94d8-4db6-81d2-67ff50c44684",
   "metadata": {},
   "source": [
    "### CSP MNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4af9741b-d112-4ffe-b473-1134bbcf36fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\sklearn\\utils\\metaestimators.py:121: FutureWarning: if_delegate_has_method was deprecated in version 1.1 and will be removed in version 1.3. Use available_if instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank=None\n",
      "    Using tolerance 57 (2.2e-16 eps * 62 dim * 4.1e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 51 (2.2e-16 eps * 62 dim * 3.7e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 71 (2.2e-16 eps * 62 dim * 5.2e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 66 (2.2e-16 eps * 62 dim * 4.8e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 57 (2.2e-16 eps * 62 dim * 4.1e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 51 (2.2e-16 eps * 62 dim * 3.7e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 71 (2.2e-16 eps * 62 dim * 5.2e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 66 (2.2e-16 eps * 62 dim * 4.8e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\sklearn\\utils\\metaestimators.py:121: FutureWarning: if_delegate_has_method was deprecated in version 1.1 and will be removed in version 1.3. Use available_if instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank=None\n",
      "    Using tolerance 56 (2.2e-16 eps * 62 dim * 4.1e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 52 (2.2e-16 eps * 62 dim * 3.8e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 70 (2.2e-16 eps * 62 dim * 5.1e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 66 (2.2e-16 eps * 62 dim * 4.8e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 56 (2.2e-16 eps * 62 dim * 4.1e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 52 (2.2e-16 eps * 62 dim * 3.8e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 70 (2.2e-16 eps * 62 dim * 5.1e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 66 (2.2e-16 eps * 62 dim * 4.8e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\sklearn\\utils\\metaestimators.py:121: FutureWarning: if_delegate_has_method was deprecated in version 1.1 and will be removed in version 1.3. Use available_if instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank=None\n",
      "    Using tolerance 55 (2.2e-16 eps * 62 dim * 4e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 49 (2.2e-16 eps * 62 dim * 3.6e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 68 (2.2e-16 eps * 62 dim * 5e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 64 (2.2e-16 eps * 62 dim * 4.7e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 55 (2.2e-16 eps * 62 dim * 4e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 49 (2.2e-16 eps * 62 dim * 3.6e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 68 (2.2e-16 eps * 62 dim * 5e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 64 (2.2e-16 eps * 62 dim * 4.7e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\sklearn\\utils\\metaestimators.py:121: FutureWarning: if_delegate_has_method was deprecated in version 1.1 and will be removed in version 1.3. Use available_if instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank=None\n",
      "    Using tolerance 52 (2.2e-16 eps * 62 dim * 3.8e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 44 (2.2e-16 eps * 62 dim * 3.2e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 65 (2.2e-16 eps * 62 dim * 4.8e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 59 (2.2e-16 eps * 62 dim * 4.3e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 52 (2.2e-16 eps * 62 dim * 3.8e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 44 (2.2e-16 eps * 62 dim * 3.2e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 65 (2.2e-16 eps * 62 dim * 4.8e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 59 (2.2e-16 eps * 62 dim * 4.3e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\sklearn\\utils\\metaestimators.py:121: FutureWarning: if_delegate_has_method was deprecated in version 1.1 and will be removed in version 1.3. Use available_if instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank=None\n",
      "    Using tolerance 54 (2.2e-16 eps * 62 dim * 3.9e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 52 (2.2e-16 eps * 62 dim * 3.8e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 68 (2.2e-16 eps * 62 dim * 5e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 65 (2.2e-16 eps * 62 dim * 4.7e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 54 (2.2e-16 eps * 62 dim * 3.9e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 52 (2.2e-16 eps * 62 dim * 3.8e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 68 (2.2e-16 eps * 62 dim * 5e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 65 (2.2e-16 eps * 62 dim * 4.7e+15  max singular value)\n",
      "    Estimated rank (mag): 62\n",
      "    MAG: rank 62 computed from 62 data channels with 0 projectors\n",
      "Reducing data rank from 62 -> 62\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alioo\\Desktop\\MA\\bbcpy_AutoML\\bbcpy_env\\lib\\site-packages\\sklearn\\utils\\metaestimators.py:121: FutureWarning: if_delegate_has_method was deprecated in version 1.1 and will be removed in version 1.3. Use available_if instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bbcpy.pipeline import make_pipeline\n",
    "import bbcpy.functions.helpers as helpers\n",
    "from bbcpy.functions.base import ImportFunc\n",
    "from mne.decoding import CSP\n",
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "var = ImportFunc(np.var, axis=2)\n",
    "# MNE csp \n",
    "n_components=[4]\n",
    "reg=0.2 #float | str | None (default None)allow regularization for covariance estimation|If float (between 0 and 1), shrinkage is used/\n",
    "log=False  # None | bool (default None)\n",
    "cov_est='concat' #‘concat’ | ‘epoch’ (default ‘concat’)\n",
    "transform_into='average_power' #‘average_power’ : the average power of each spatial filter| ‘csp_space’ :  the data in CSP space(default ‘average_power’)\n",
    "norm_trace=True # bool (default False) Normalize class covariance by its trace.\n",
    "cov_method_params=None #dict | None Parameters to pass to mne.compute_covariance().\n",
    "rank=None #None | ‘info’ | ‘full’ | dict\n",
    "component_order='mutual_info' #‘mutual_info’ | ‘alternate’ (default ‘mutual_info’) \n",
    "\n",
    "results = []\n",
    "for filter in n_components:\n",
    "    csp = CSP(n_components=filter,\n",
    "              reg=reg,\n",
    "              log=log,\n",
    "              cov_est=cov_est,\n",
    "              transform_into=transform_into,\n",
    "              norm_trace=norm_trace,\n",
    "              cov_method_params=cov_method_params,\n",
    "              rank=rank,\n",
    "              component_order=component_order)\n",
    "    \n",
    "    csp_pipeline = make_pipeline(   csp,\n",
    "                                    var,\n",
    "                                    np.log,\n",
    "                                    LDA()\n",
    "                                )\n",
    "    \n",
    "    # Perform cross-validation and store the results\n",
    "    scores = cross_val_score(csp_pipeline, train_data, train_data.y, cv=cv, error_score='raise')\n",
    "\n",
    "    # Store results for each fold\n",
    "    for i, score in enumerate(scores):\n",
    "        results.append([filter, i+1, score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31bb8ba1-fecc-4550-977f-81d1dfb3255b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4, 1, 0.6276595744680851],\n",
       " [4, 2, 0.5851063829787234],\n",
       " [4, 3, 0.44086021505376344],\n",
       " [4, 4, 0.5268817204301075],\n",
       " [4, 5, 0.5483870967741935]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaa2be5-0fa6-47d1-b593-ed3a96245c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the results\n",
    "file_name = 'filter_results_csp_MNE.csv'\n",
    "results_df = pd.DataFrame(results, columns = ['filter', 'fold', 'score'])\n",
    "results_df.to_csv(os.path.join(run_path, file_name), index=False)\n",
    "\n",
    "# Calculate mean and standard deviation for each excllev value\n",
    "summary_df = results_df.groupby('filter')[['score']].agg(['mean', 'std'])\n",
    "summary_df\n",
    "file_name = 'filter_summary_csp_MNE.csv'\n",
    "summary_df.to_csv(os.path.join(run_path, file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f7c4d2-1eac-44bc-8983-41453777f3b5",
   "metadata": {},
   "source": [
    "## Riemann "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3c8ea7453a8fc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T13:13:56.327175500Z",
     "start_time": "2023-10-28T13:13:56.264651400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pyriemann\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import bbcpy\n",
    "from bbcpy.functions.artireject import AverageVariance\n",
    "from bbcpy.pipeline import make_pipeline\n",
    "from bbcpy.functions.base import ImportFunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f1491bbb6f95b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T13:18:32.104358200Z",
     "start_time": "2023-10-28T13:16:57.368260200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the values of excllev to investigate\n",
    "excllev_values = [None, 1.2, 1.8, 2, 4, 8, 10, 20, 100]\n",
    "estimator = 'lwf'\n",
    "# Initialize an empty list to store results\n",
    "results = []\n",
    "\n",
    "for excllev in excllev_values:\n",
    "    # AverageVariance(excllev=filter, estimator=estimator)\n",
    "    Cov = ImportFunc(bbcpy.functions.statistics.cov, estimator=estimator)\n",
    "    riemann_pipeline = make_pipeline(AverageVariance(excllev=excllev, estimator=estimator),\n",
    "                                     Cov,\n",
    "                                     pyriemann.classification.SVC(metric='riemann', class_weight=class_weights_dict, decision_function_shape=\"ovo\"))\n",
    "    # Perform cross-validation and store the results\n",
    "    scores = cross_val_score(riemann_pipeline, train_data, train_data.y, cv=cv, error_score='raise')\n",
    "   \n",
    "    # Store results for each fold\n",
    "    for i, score in enumerate(scores):\n",
    "        results.append([excllev, i+1, score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f788b3e733685c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T13:16:25.851176600Z",
     "start_time": "2023-10-28T13:14:01.570688300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results, columns=['excllev', 'fold', 'score'])\n",
    "file_name = 'excllev_results_Riemann_bbcpy.csv'\n",
    "results_df.to_csv(os.path.join(run_path, file_name), index=False)\n",
    "\n",
    "# Calculate mean and standard deviation for each excllev value\n",
    "summary_df = results_df.groupby('excllev')[['score']].agg(['mean', 'std'])\n",
    "summary_df\n",
    "file_name = 'excllev_summary_Riemann_bbcpy.csv'\n",
    "summary_df.to_csv(os.path.join(run_path, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626901f5-d05f-4803-bd08-d761eaa47ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475bb7b3-5330-4b10-a996-d66f6a7ac0bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T13:20:57.565367900Z",
     "start_time": "2023-10-28T13:18:32.104358200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Tangent Rieamnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece2a6cc-86f9-43bb-bbb9-41ad5678dd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the values of excllev to investigate\n",
    "excllev_values = [None, 1.2, 1.8, 2, 4, 8, 10, 20, 100]\n",
    "estimator = 'lwf'\n",
    "# Initialize an empty list to store results\n",
    "results = []\n",
    "for excllev in excllev_values:\n",
    "\n",
    "    Triemann_pipeline = make_pipeline(AverageVariance(excllev=excllev, estimator=estimator),\n",
    "                                      ImportFunc(bbcpy.functions.statistics.cov, estimator=estimator),\n",
    "                                      pyriemann.tangentspace.TangentSpace(),\n",
    "                                      sklearn.svm.SVC(class_weight=class_weights_dict, decision_function_shape=\"ovo\"))\n",
    "    # Perform cross-validation and store the results\n",
    "    scores = cross_val_score(Triemann_pipeline, train_data, train_data.y, cv=cv, error_score='raise')\n",
    "    \n",
    "    # Store results for each fold\n",
    "    for i, score in enumerate(scores):\n",
    "        results.append([excllev, i+1, score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca29640-e508-4b23-b7fa-4e38138db70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results, columns=['excllev', 'fold', 'score'])\n",
    "file_name = 'excllev_results_TRiemann_bbcpy.csv'\n",
    "results_df.to_csv(os.path.join(run_path, file_name), index=False)\n",
    "\n",
    "# Calculate mean and standard deviation for each excllev value\n",
    "summary_df = results_df.groupby('excllev')[['score']].agg(['mean', 'std'])\n",
    "summary_df\n",
    "file_name = 'excllev_summary_TRiemann_bbcpy.csv'\n",
    "summary_df.to_csv(os.path.join(run_path, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60c3d99-8998-4625-a4da-ce36d560da0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd07597f-2194-4180-acf3-ac7dc67ddce4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
