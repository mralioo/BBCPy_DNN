{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Visualising statistical significance thresholds on EEG data\n",
    "\n",
    "MNE-Python provides a range of tools for statistical hypothesis testing\n",
    "and the visualisation of the results. Here, we show a few options for\n",
    "exploratory and confirmatory tests - e.g., targeted t-tests, cluster-based\n",
    "permutation approaches (here with Threshold-Free Cluster Enhancement);\n",
    "and how to visualise the results.\n",
    "\n",
    "The underlying data comes from :footcite:`DufauEtAl2015`; we contrast long vs.\n",
    "short words. TFCE is described in :footcite:`SmithNichols2009`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "import mne\n",
    "from mne.channels import find_ch_adjacency, make_1020_channel_selections\n",
    "from mne.stats import spatio_temporal_cluster_test\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Load the data\n",
    "path = mne.datasets.kiloword.data_path() / \"kword_metadata-epo.fif\"\n",
    "epochs = mne.read_epochs(path)\n",
    "# These data are quite smooth, so to speed up processing we'll (unsafely!) just\n",
    "# decimate them\n",
    "epochs.decimate(4, verbose=\"error\")\n",
    "name = \"NumberOfLetters\"\n",
    "\n",
    "# Split up the data by the median length in letters via the attached metadata\n",
    "median_value = str(epochs.metadata[name].median())\n",
    "long_words = epochs[name + \" > \" + median_value]\n",
    "short_words = epochs[name + \" < \" + median_value]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have a specific point in space and time we wish to test, it can be\n",
    "convenient to convert the data into Pandas Dataframe format. In this case,\n",
    "the :class:`mne.Epochs` object has a convenient\n",
    ":meth:`mne.Epochs.to_data_frame` method, which returns a dataframe.\n",
    "This dataframe can then be queried for specific time windows and sensors.\n",
    "The extracted data can be submitted to standard statistical tests. Here,\n",
    "we conduct t-tests on the difference between long and short words.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "time_windows = ((0.2, 0.25), (0.35, 0.45))\n",
    "elecs = [\"Fz\", \"Cz\", \"Pz\"]\n",
    "index = [\"condition\", \"epoch\", \"time\"]\n",
    "\n",
    "# display the EEG data in Pandas format (first 5 rows)\n",
    "print(epochs.to_data_frame(index=index)[elecs].head())\n",
    "\n",
    "report = \"{elec}, time: {tmin}-{tmax} s; t({df})={t_val:.3f}, p={p:.3f}\"\n",
    "print(\"\\nTargeted statistical test results:\")\n",
    "for tmin, tmax in time_windows:\n",
    "    long_df = long_words.copy().crop(tmin, tmax).to_data_frame(index=index)\n",
    "    short_df = short_words.copy().crop(tmin, tmax).to_data_frame(index=index)\n",
    "    for elec in elecs:\n",
    "        # extract data\n",
    "        A = long_df[elec].groupby(\"condition\").mean()\n",
    "        B = short_df[elec].groupby(\"condition\").mean()\n",
    "\n",
    "        # conduct t test\n",
    "        t, p = ttest_ind(A, B)\n",
    "\n",
    "        # display results\n",
    "        format_dict = dict(\n",
    "            elec=elec, tmin=tmin, tmax=tmax, df=len(epochs.events) - 2, t_val=t, p=p\n",
    "        )\n",
    "        print(report.format(**format_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Absent specific hypotheses, we can also conduct an exploratory\n",
    "mass-univariate analysis at all sensors and time points. This requires\n",
    "correcting for multiple tests.\n",
    "MNE offers various methods for this; amongst them, cluster-based permutation\n",
    "methods allow deriving power from the spatio-temoral correlation structure\n",
    "of the data. Here, we use TFCE.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Calculate adjacency matrix between sensors from their locations\n",
    "adjacency, _ = find_ch_adjacency(epochs.info, \"eeg\")\n",
    "\n",
    "# Extract data: transpose because the cluster test requires channels to be last\n",
    "# In this case, inference is done over items. In the same manner, we could\n",
    "# also conduct the test over, e.g., subjects.\n",
    "X = [\n",
    "    long_words.get_data().transpose(0, 2, 1),\n",
    "    short_words.get_data().transpose(0, 2, 1),\n",
    "]\n",
    "tfce = dict(start=0.4, step=0.4)  # ideally start and step would be smaller\n",
    "\n",
    "# Calculate statistical thresholds\n",
    "t_obs, clusters, cluster_pv, h0 = spatio_temporal_cluster_test(\n",
    "    X, tfce, adjacency=adjacency, n_permutations=100\n",
    ")  # a more standard number would be 1000+\n",
    "significant_points = cluster_pv.reshape(t_obs.shape).T < 0.05\n",
    "print(str(significant_points.sum()) + \" points selected by TFCE ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of these mass univariate analyses can be visualised by plotting\n",
    ":class:`mne.Evoked` objects as images (via :class:`mne.Evoked.plot_image`)\n",
    "and masking points for significance.\n",
    "Here, we group channels by Regions of Interest to facilitate localising\n",
    "effects on the head.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# We need an evoked object to plot the image to be masked\n",
    "evoked = mne.combine_evoked(\n",
    "    [long_words.average(), short_words.average()], weights=[1, -1]\n",
    ")  # calculate difference wave\n",
    "time_unit = dict(time_unit=\"s\")\n",
    "evoked.plot_joint(\n",
    "    title=\"Long vs. short words\", ts_args=time_unit, topomap_args=time_unit\n",
    ")  # show difference wave\n",
    "\n",
    "# Create ROIs by checking channel labels\n",
    "selections = make_1020_channel_selections(evoked.info, midline=\"12z\")\n",
    "\n",
    "# Visualize the results\n",
    "fig, axes = plt.subplots(nrows=3, figsize=(8, 8))\n",
    "axes = {sel: ax for sel, ax in zip(selections, axes.ravel())}\n",
    "evoked.plot_image(\n",
    "    axes=axes,\n",
    "    group_by=selections,\n",
    "    colorbar=False,\n",
    "    show=False,\n",
    "    mask=significant_points,\n",
    "    show_names=\"all\",\n",
    "    titles=None,\n",
    "    **time_unit,\n",
    ")\n",
    "plt.colorbar(axes[\"Left\"].images[-1], ax=list(axes.values()), shrink=0.3, label=\"ÂµV\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    ".. footbibliography::\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
