{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T11:42:07.729095200Z",
     "start_time": "2023-10-24T11:42:07.712101Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the directory where your CSV files are stored\n",
    "csv_dir = \"../local/21_10/results\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ccee99-9aad-4355-8b78-7b353b26b4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load CSV files and extract relevant information\n",
    "for csv_file in os.listdir(csv_dir):\n",
    "    if csv_file.endswith(\".csv\"):\n",
    "\n",
    "        csv_file_name = os.path.splitext(csv_file)[0]\n",
    "\n",
    "        if len(csv_file_name.split(\"_\")) == 3:\n",
    "            task, model, subject = csv_file_name.split(\"_\")\n",
    "        else:\n",
    "            task, _, model, subject = csv_file_name.split(\"_\")\n",
    "            \n",
    "        df = pd.read_csv(os.path.join(csv_dir, csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b44a89-221e-43f0-904e-157fce6ca3d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6ad8f0fe8fecf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T11:45:34.675242600Z",
     "start_time": "2023-10-24T11:45:34.659081100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# # Step 3: Organize the metrics data\n",
    "# def extract_metric(df, metric_name):\n",
    "#     # Look for columns starting with 'val/' or 'mean_val/'\n",
    "#     relevant_columns = [col for col in df.columns if col.startswith(('val/', 'mean_val/'))]\n",
    "#     metric_columns = [col for col in relevant_columns if metric_name in col]\n",
    "#     return df[metric_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd563603d360090",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T11:45:35.090686800Z",
     "start_time": "2023-10-24T11:45:35.058816200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# def extract_metric(df, metric_name):\n",
    "#     relevant_columns = [col for col in df.columns if col.startswith(('val/', 'mean_val/'))]\n",
    "#     metric_columns = [col for col in relevant_columns if metric_name in col]\n",
    "#     return df[metric_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb07307482f28404",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "data_lr = {}\n",
    "data_2D = {}\n",
    "\n",
    "# Function to process CSV data\n",
    "def process_csv_data(csv_data):\n",
    "    # Assuming data_type1 and data_type2 are the strings containing your respective CSV data.\n",
    "\n",
    "    # For type 1\n",
    "    type1_df = pd.read_csv(pd.compat.StringIO(csv_data), header=None, names=['column'])\n",
    "\n",
    "    # Extract mean_test and mean_val columns\n",
    "    type1_df = type1_df[type1_df['column'].str.startswith(('mean_test', 'mean_val'))]\n",
    "\n",
    "    # Split column into original column name and dictionary\n",
    "    type1_df[['original_column', 'dictionary']] = type1_df['column'].str.split(',', expand=True)\n",
    "\n",
    "    # Extract values from the dictionary\n",
    "    type1_df = pd.concat([type1_df, type1_df['dictionary'].apply(lambda x: pd.Series(eval(x)))], axis=1)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    type1_df = type1_df.drop(columns=['column', 'dictionary'])\n",
    "\n",
    "    return type1_df\n",
    "\n",
    "# Step 1: Load CSV files and extract relevant information\n",
    "for csv_file in os.listdir(csv_dir):\n",
    "    if csv_file.endswith(\".csv\"):\n",
    "\n",
    "        csv_file_name = os.path.splitext(csv_file)[0]\n",
    "\n",
    "        if len(csv_file_name.split(\"_\")) == 3:\n",
    "            task, model, subject = csv_file_name.split(\"_\")\n",
    "        else:\n",
    "            task, _, model, subject = csv_file_name.split(\"_\")\n",
    "            \n",
    "        \n",
    "        \n",
    "        df = pd.read_csv(os.path.join(csv_dir, csv_file))\n",
    "        \n",
    "        if \n",
    "        \n",
    "        \n",
    "        # df.columns = df.columns.str.replace('mean_', '')  # Remove \"mean_\" prefix\n",
    "\n",
    "        # Step 2: Separate LR and 2D data\n",
    "        if task == \"LR\":\n",
    "            if model in data_lr:\n",
    "                data_lr[model].append(df.assign(subject_name=subject))\n",
    "            else:\n",
    "                data_lr[model] = [df.assign(subject_name=subject)]\n",
    "        if task == \"2D\":\n",
    "            if model in data_2D:\n",
    "                data_2D[model].append(df.assign(subject_name=subject))\n",
    "            else:\n",
    "                data_2D[model] = [df.assign(subject_name=subject)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b0c9f8a35dc890",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Process LR Data\n",
    "for model, dfs in data_lr.items():\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    combined_df = combined_df[combined_df['subject_name'].notna()]\n",
    "    acc_lr_data = combined_df.filter(like='acc').set_index('subject_name').drop_duplicates()\n",
    "    f1_lr_data = combined_df.filter(like='f1').set_index('subject_name').drop_duplicates()\n",
    "\n",
    "    # Further processing as needed\n",
    "\n",
    "# Process 2D Data\n",
    "for model, dfs in data_2D.items():\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    combined_df = combined_df[combined_df['subject_name'].notna()]\n",
    "    acc_2D_data = combined_df.filter(like='acc').set_index('subject_name').drop_duplicates()\n",
    "    f1_2D_data = combined_df.filter(like='f1').set_index('subject_name').drop_duplicates()\n",
    "\n",
    "    # Further processing as needed\n",
    "\n",
    "# Step 3: Process CSV data (assuming you have data_type1 and data_type2)\n",
    "data_type1 = \"your_csv_data_for_type1_here\"\n",
    "data_type2 = \"your_csv_data_for_type2_here\"\n",
    "\n",
    "type1_df = process_csv_data(data_type1)\n",
    "type2_df = process_csv_data(data_type2)\n",
    "\n",
    "# Renaming the columns\n",
    "type1_df = type1_df.rename(columns=lambda x: f'mean_{x}')\n",
    "type2_df = type2_df.rename(columns=lambda x: f'mean_{x}')\n",
    "\n",
    "# Combining both dataframes (if needed)\n",
    "combined_df = pd.concat([type1_df, type2_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62843368fb71fe7c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-24T12:18:35.932086600Z"
    },
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 3: Process the data\n",
    "# Initialize an empty dictionary to store DataFrames for each model\n",
    "# Define the directory where your CSV files are stored\n",
    "csv_dir = \"../local/21_10/results\"\n",
    "\n",
    "data_lr = {}\n",
    "data_2D = {}\n",
    "\n",
    "# Step 1: Load CSV files and extract relevant information\n",
    "for csv_file in os.listdir(csv_dir):\n",
    "    if csv_file.endswith(\".csv\"):\n",
    "\n",
    "        csv_file_name = os.path.splitext(csv_file)[0]\n",
    "        # print(csv_file_name)\n",
    "        # print(csv_file_name.split(\"_\"))\n",
    "\n",
    "        if len(csv_file_name.split(\"_\")) == 3:\n",
    "            task, model, subject = csv_file_name.split(\"_\")\n",
    "        else:\n",
    "            task, _, model, subject = csv_file_name.split(\"_\")\n",
    "        \n",
    "        df = pd.read_csv(os.path.join(csv_dir, csv_file))\n",
    "        df.columns = df.columns.str.replace('mean_', '')  # Remove \"mean_\" prefix\n",
    "\n",
    "        # Step 2: Separate LR and 2D data\n",
    "        if task == \"LR\":\n",
    "            if model in data_lr:\n",
    "                data_lr[model].append(df.assign(subject_name=subject))\n",
    "            else:\n",
    "                data_lr[model] = [df.assign(subject_name=subject)]\n",
    "        if task == \"2D\":\n",
    "            if model in data_2D:\n",
    "                data_2D[model].append(df.assign(subject_name=subject))\n",
    "            else:\n",
    "                data_2D[model] = [df.assign(subject_name=subject)]\n",
    "\n",
    "def extract_metric(df, metric_name):\n",
    "    if 'mean_' + metric_name in df.columns:\n",
    "        return df[df['subject_name'].notna()][['subject_name', 'mean_' + metric_name]]\n",
    "    else:\n",
    "        return df[df['subject_name'].notna()]['subject_name'].apply(lambda x: x[1:-1][metric_name]).reset_index(drop=True)\n",
    "\n",
    "# Example usage\n",
    "acc_lr_data = {}\n",
    "f1_lr_data = {}\n",
    "acc_2D_data = {}\n",
    "f1_2D_data = {}\n",
    "\n",
    "# Step 3: Process the data\n",
    "for model, dfs in data_lr.items():\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    acc_lr_data[model]  = extract_metric(combined_df, 'acc').set_index('subject_name').drop_duplicates()\n",
    "    f1_lr_data[model] = extract_metric(combined_df, 'f1').set_index('subject_name').drop_duplicates()\n",
    "\n",
    "for model, dfs in data_2D.items():\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    acc_2D_data[model]  = extract_metric(combined_df, 'acc').set_index('subject_name').drop_duplicates()\n",
    "    f1_2D_data[model] = extract_metric(combined_df, 'f1').set_index('subject_name').drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa8431618a1ecd2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-24T12:16:12.793645800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# def extract_metric(df, metric_name):\n",
    "#     print(df)\n",
    "#     if 'mean_' + metric_name in df.columns:\n",
    "#         relevant_columns = [col for col in df.columns if col.startswith(('mean_val/'))]\n",
    "#         metric_columns = [col for col in relevant_columns if metric_name in col]\n",
    "#         return df[['subject_name'] + metric_columns]   # Include 'subject' column in the result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e4bc10dcdfe9c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T11:49:10.365533800Z",
     "start_time": "2023-10-24T11:49:10.266226700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "acc_lr_data = {}\n",
    "f1_lr_data = {}\n",
    "acc_2D_data = {}\n",
    "f1_2D_data = {}\n",
    "\n",
    "# Step 3: Process the data\n",
    "for model, dfs in data_lr.items():\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    acc_lr_data[model]  = extract_metric(combined_df, 'acc').set_index('subject_name').drop_duplicates()\n",
    "    f1_lr_data[model] = extract_metric(combined_df, 'f1').set_index('subject_name').drop_duplicates()\n",
    "    \n",
    "    \n",
    "for model, dfs in data_2D.items():\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    acc_2D_data[model]  = extract_metric(combined_df, 'acc').set_index('subject_name').drop_duplicates()\n",
    "    f1_2D_data[model] = extract_metric(combined_df, 'f1').set_index('subject_name').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6833e1fa880c83e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T11:49:11.000026100Z",
     "start_time": "2023-10-24T11:49:10.966147200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "f1_2D_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fc61c54c74f5ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T11:49:13.066316300Z",
     "start_time": "2023-10-24T11:49:13.033110400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "acc_2D_data[\"csp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46904e00bea739a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T13:09:38.370182800Z",
     "start_time": "2023-10-17T13:09:38.354568200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Assuming 'subject_name' is the column that contains subject names\n",
    "# acc_lr_data = [(model, extract_metric(pd.concat([df.assign(subject_name=subject) for model, subject, df in task_LR_data if model == model], ignore_index=True), 'acc').set_index('subject_name').drop_duplicates()) for model, _, _ in task_LR_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b91939c9ad72dd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T13:09:42.238204900Z",
     "start_time": "2023-10-17T13:09:41.793948400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming acc_lr_data is a dictionary where keys are model names and values are DataFrames\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "x_positions = np.arange(len(acc_lr_data))\n",
    "\n",
    "for i, (model, df) in enumerate(acc_lr_data.items()):\n",
    "    avg_acc = df[['val/acc']].mean(axis=1, skipna=True)\n",
    "    \n",
    "    # Adjust the x position for each boxplot\n",
    "    plt.boxplot(avg_acc.values, positions=[i])\n",
    "\n",
    "    \n",
    "plt.title('Boxplot for Model Performance LR task')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.xticks(x_positions, [model for model, _ in acc_lr_data.items()], rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f1e7c460e8272f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T13:09:46.654047900Z",
     "start_time": "2023-10-17T13:09:46.080142400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming acc_lr_data is a dictionary where keys are model names and values are DataFrames\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "x_positions = np.arange(len(acc_2D_data))\n",
    "\n",
    "for i, (model, df) in enumerate(acc_2D_data.items()):\n",
    "    avg_acc = df[['val/acc']].mean(axis=1, skipna=True)\n",
    "    \n",
    "    # Adjust the x position for each boxplot\n",
    "    plt.boxplot(avg_acc.values, positions=[i])\n",
    "\n",
    "    \n",
    "plt.title('Boxplot for Model Performance 2D task')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.xticks(x_positions, [model for model, _ in acc_2D_data.items()], rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418d498db635e976",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T13:07:37.915834800Z",
     "start_time": "2023-10-17T13:07:31.816561900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1561f581929ec47e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T13:09:55.931024700Z",
     "start_time": "2023-10-17T13:09:55.101220100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Assuming acc_lr_data is a dictionary where keys are model names and values are DataFrames\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Create lists to store subject names and average accuracies\n",
    "subject_names = []\n",
    "avg_accuracies = []\n",
    "\n",
    "# Iterate through the acc_lr_data dictionary\n",
    "for i, (model, df) in enumerate(acc_lr_data.items()):\n",
    "    avg_acc = df[['val/acc']].mean(axis=1, skipna=True)\n",
    "    \n",
    "    # Add subject names and corresponding average accuracies\n",
    "    subject_names.extend([model] * len(avg_acc))\n",
    "    avg_accuracies.extend(avg_acc)\n",
    "    \n",
    "    # Adjust the x position for each boxplot\n",
    "    plt.boxplot(avg_acc.values, positions=[i])\n",
    "\n",
    "# Add Gaussian distribution plot\n",
    "x = np.linspace(min(avg_accuracies), max(avg_accuracies), 100)\n",
    "pdf = stats.norm.pdf(x, np.mean(avg_accuracies), np.std(avg_accuracies))\n",
    "plt.plot(x, pdf, color='red')\n",
    "\n",
    "# Add subject names as dots\n",
    "plt.scatter(range(len(subject_names)), avg_accuracies, c='black', marker='o', s=10)\n",
    "\n",
    "plt.title('Model Performance')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.xticks(range(len(acc_lr_data)), [model for model, _ in acc_lr_data.items()], rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285203e21a3061e6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bbcpy_env",
   "language": "python",
   "name": "bbcpy_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
