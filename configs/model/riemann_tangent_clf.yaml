_target_: src.models.baseline_models.classifier_pipeline
steps_config: # use yaml list syntax to preserve to order
  FeatureExtraction:
    AverageVariance:
      applied: True
      excllev: null
      estimator: 'lwf'
    Covariance:
      applied: True
      estimator: 'lwf'
      axis: -2 # axis: -1 for time, -2 (default) for channels, 0 for epochs
  Transformation:
    tangent_space:
      applied: True
      metric: 'riemann' # 'riemann' | 'logeuclid' | 'euclid'
  Classification:
    SVC-sklearn:
      applied: True
      class_weight: balanced # dict or ‘balanced’, default=None ; Set the parameter C of class i to class_weight[i]*C for SVC. If not given, all classes are supposed to have weight one. The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y))
      C: 1.0 # float, default=1.0 ; Regularization parameter. The strength of the regularization is inversely proportional to C. Must be strictly positive. The penalty is a squared l2 penalty.
      kernel: rbf # {‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’}, default=’rbf’ ; Specifies the kernel type to be used in the algorithm. It must be one of ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’ or a callable. If none is given, ‘rbf’ will be used. If a callable is given it is used to pre-compute the kernel matrix from data matrices; that matrix should be an array of shape (n_samples, n_samples).
      degree: 3 # int, default=3 ; Degree of the polynomial kernel function (‘poly’). Ignored by all other kernels.
      gamma: scale # {‘scale’, ‘auto’} or float, default=’scale’ ; Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’. If gamma='scale' (default) is passed then it uses 1 / (n_features * X.var()) as value of gamma, if ‘auto’, uses 1 / n_features.
      coef0: 0.0 # float, default=0.0 ; Independent term in kernel function. It is only significant in ‘poly’ and ‘sigmoid’.
      shrinking: True # bool, default=True ; Whether to use the shrinking heuristic.
      probability: True # bool, default=False ; Whether to enable probability estimates. This must be enabled prior to calling fit, and will slow down that method.
      tol: 1e-3 # float, default=1e-3 ; Tolerance for stopping criterion.
      cache_size: 200 # float, default=200 ; Specify the size of the kernel cache (in MB).
      verbose: False # bool, default=False ; Enable verbose output. Note that this setting takes advantage of a per-process runtime setting in libsvm that, if enabled, may not work properly in a multithreaded context.
      max_iter: -1 # int, default=-1 ; Hard limit on iterations within solver, or -1 for no limit.
      decision_function_shape: ovr # {‘ovo’, ‘ovr’}, default=’ovr’ ; Whether to return a one-vs-rest (‘ovr’) decision function of shape (n_samples, n_classes) as all other classifiers, or the original one-vs-one (‘ovo’) decision function of libsvm which has shape (n_samples, n_classes * (n_classes - 1) / 2).
      break_ties: False # bool, default=False ; If true, decision_function_shape=’ovr’, and number of classes > 2, predict will break ties according to the confidence values of decision_function; otherwise the first class among the tied classes is returned. Please note that breaking ties comes at a relatively high computational cost compared to a simple predict.
      random_state: null # int, RandomState instance or None, default=None ; Controls the pseudo random number generation for shuffling the data for probability estimates. Ignored when probability is False. Pass an int for reproducible output across multiple function calls.